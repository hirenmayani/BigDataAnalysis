{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine_tuning_squad.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hirenmayani/BigDataAnalysis/blob/master/fine_tuning_squad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "765BFKBvakDO",
        "colab_type": "code",
        "outputId": "f52a6769-92be-4f83-b8e9-8764c4dea349",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cb0f2e9a-4ddb-4e21-81be-6c7cb959688a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-cb0f2e9a-4ddb-4e21-81be-6c7cb959688a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving uncased_L-12_H-768_A-12.zip to uncased_L-12_H-768_A-12.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TBO17MxCazKT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "r_lwbIT6XOvl",
        "colab_type": "code",
        "outputId": "7261ff86-6e85-4624-fd6a-908c3fcb5deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "euVOIGxEjj7O",
        "colab_type": "code",
        "outputId": "74bb33ef-2295-441f-e745-e753b1319d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!mv 'qna_sbu (1).json' qna_sbu.json\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_model.ckpt.data-00000-of-00001  qna_sbu.json\n",
            "download_glue_repo\t\t     sample_data\n",
            "glue_data\t\t\t     tokenization.py\n",
            "modeling.py\t\t\t     uncased_L-12_H-768_A-12\n",
            "optimization.py\t\t\t     uncased_L-12_H-768_A-12.zip\n",
            "__pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rERgDuNUWMyQ",
        "colab_type": "code",
        "outputId": "2cfed562-2ed3-4b4c-db15-59725a1b70f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "TASK = 'qna_sbu'\n",
        "TASK_DATA_DIR = TASK+'.json'\n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "!ls $TASK_DATA_DIR\n",
        "\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "BERT_PRETRAINED_DIR = BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "\n",
        "\n",
        "OUTPUT_DIR = '/Downloads/output'\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Task data directory: qna_sbu.json *****\n",
            "ls: cannot access 'qna_sbu.json': No such file or directory\n",
            "***** BERT pretrained directory: uncased_L-12_H-768_A-12 *****\n",
            "***** Model output directory: /Downloads/output *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pWod0J3J3BOa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "import six\n",
        "import tensorflow as tf\n",
        "\n",
        "flags = tf.flags\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "## Required parameters\n",
        "flags.DEFINE_string(\n",
        "    \"bert_config_file\", BERT_MODEL+'/bert_config.json',\n",
        "    \"The config json file corresponding to the pre-trained BERT model. \"\n",
        "    \"This specifies the model architecture.\")\n",
        "\n",
        "flags.DEFINE_string(\"vocab_file\", BERT_MODEL+'/vocab.txt',\n",
        "                    \"The vocabulary file that the BERT model was trained on.\")\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    \"output_dir\", OUTPUT_DIR,\n",
        "    \"The output directory where the model checkpoints will be written.\")\n",
        "\n",
        "## Other parameters\n",
        "flags.DEFINE_string(\"train_file\", TASK+'.json',\n",
        "                    \"SQuAD json for training. E.g., train-v1.1.json\")\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    \"predict_file\", None,\n",
        "    \"SQuAD json for predictions. E.g., dev-v1.1.json or test-v1.1.json\")\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    \"init_checkpoint\", None,\n",
        "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
        "\n",
        "flags.DEFINE_bool(\n",
        "    \"do_lower_case\", True,\n",
        "    \"Whether to lower case the input text. Should be True for uncased \"\n",
        "    \"models and False for cased models.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"max_seq_length\", 384,\n",
        "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
        "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
        "    \"than this will be padded.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"doc_stride\", 128,\n",
        "    \"When splitting up a long document into chunks, how much stride to \"\n",
        "    \"take between chunks.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"max_query_length\", 64,\n",
        "    \"The maximum number of tokens for the question. Questions longer than \"\n",
        "    \"this will be truncated to this length.\")\n",
        "\n",
        "flags.DEFINE_bool(\"do_train\", True, \"Whether to run training.\")\n",
        "\n",
        "flags.DEFINE_bool(\"do_predict\", False, \"Whether to run eval on the dev set.\")\n",
        "\n",
        "flags.DEFINE_integer(\"train_batch_size\", 32, \"Total batch size for training.\")\n",
        "\n",
        "flags.DEFINE_integer(\"predict_batch_size\", 8,\n",
        "                     \"Total batch size for predictions.\")\n",
        "\n",
        "flags.DEFINE_float(\"learning_rate\", 5e-5, \"The initial learning rate for Adam.\")\n",
        "\n",
        "flags.DEFINE_float(\"num_train_epochs\", 3.0,\n",
        "                   \"Total number of training epochs to perform.\")\n",
        "\n",
        "flags.DEFINE_float(\n",
        "    \"warmup_proportion\", 0.1,\n",
        "    \"Proportion of training to perform linear learning rate warmup for. \"\n",
        "    \"E.g., 0.1 = 10% of training.\")\n",
        "\n",
        "flags.DEFINE_integer(\"save_checkpoints_steps\", 1000,\n",
        "                     \"How often to save the model checkpoint.\")\n",
        "\n",
        "flags.DEFINE_integer(\"iterations_per_loop\", 1000,\n",
        "                     \"How many steps to make in each estimator call.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"n_best_size\", 20,\n",
        "    \"The total number of n-best predictions to generate in the \"\n",
        "    \"nbest_predictions.json output file.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"max_answer_length\", 30,\n",
        "    \"The maximum length of an answer that can be generated. This is needed \"\n",
        "    \"because the start and end predictions are not conditioned on one another.\")\n",
        "\n",
        "flags.DEFINE_bool(\"use_tpu\", False, \"Whether to use TPU or GPU/CPU.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\n",
        "    \"tpu_name\", None,\n",
        "    \"The Cloud TPU to use for training. This should be either the name \"\n",
        "    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\n",
        "    \"url.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\n",
        "    \"tpu_zone\", None,\n",
        "    \"[Optional] GCE zone where the Cloud TPU is located in. If not \"\n",
        "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
        "    \"metadata.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\n",
        "    \"gcp_project\", None,\n",
        "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
        "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
        "    \"metadata.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\"master\", None, \"[Optional] TensorFlow master URL.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"num_tpu_cores\", 8,\n",
        "    \"Only used if `use_tpu` is True. Total number of TPU cores to use.\")\n",
        "\n",
        "flags.DEFINE_bool(\n",
        "    \"verbose_logging\", False,\n",
        "    \"If true, all of the warnings related to data processing will be printed. \"\n",
        "    \"A number of warnings are expected for a normal SQuAD evaluation.\")\n",
        "\n",
        "flags.DEFINE_bool(\n",
        "    \"version_2_with_negative\", False,\n",
        "    \"If true, the SQuAD examples contain some that do not have an answer.\")\n",
        "\n",
        "flags.DEFINE_float(\n",
        "    \"null_score_diff_threshold\", 0.0,\n",
        "    \"If null_score - best_non_null is greater than the threshold predict null.\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YO1nMl-2ujng",
        "colab_type": "code",
        "outputId": "7a64300a-20f3-4e22-8621-dc37dbfacec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14399
        }
      },
      "cell_type": "code",
      "source": [
        "class SquadExample(object):\n",
        "  \"\"\"A single training/test example for simple sequence classification.\n",
        "\n",
        "     For examples without an answer, the start and end position are -1.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               qas_id,\n",
        "               question_text,\n",
        "               doc_tokens,\n",
        "               orig_answer_text=None,\n",
        "               start_position=None,\n",
        "               end_position=None,\n",
        "               is_impossible=False):\n",
        "    self.qas_id = qas_id\n",
        "    self.question_text = question_text\n",
        "    self.doc_tokens = doc_tokens\n",
        "    self.orig_answer_text = orig_answer_text\n",
        "    self.start_position = start_position\n",
        "    self.end_position = end_position\n",
        "    self.is_impossible = is_impossible\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.__repr__()\n",
        "\n",
        "  def __repr__(self):\n",
        "    s = \"\"\n",
        "    s += \"qas_id: %s\" % (tokenization.printable_text(self.qas_id))\n",
        "    s += \", question_text: %s\" % (\n",
        "        tokenization.printable_text(self.question_text))\n",
        "    s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n",
        "    if self.start_position:\n",
        "      s += \", start_position: %d\" % (self.start_position)\n",
        "    if self.start_position:\n",
        "      s += \", end_position: %d\" % (self.end_position)\n",
        "    if self.start_position:\n",
        "      s += \", is_impossible: %r\" % (self.is_impossible)\n",
        "    return s\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "  \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               unique_id,\n",
        "               example_index,\n",
        "               doc_span_index,\n",
        "               tokens,\n",
        "               token_to_orig_map,\n",
        "               token_is_max_context,\n",
        "               input_ids,\n",
        "               input_mask,\n",
        "               segment_ids,\n",
        "               start_position=None,\n",
        "               end_position=None,\n",
        "               is_impossible=None):\n",
        "    self.unique_id = unique_id\n",
        "    self.example_index = example_index\n",
        "    self.doc_span_index = doc_span_index\n",
        "    self.tokens = tokens\n",
        "    self.token_to_orig_map = token_to_orig_map\n",
        "    self.token_is_max_context = token_is_max_context\n",
        "    self.input_ids = input_ids\n",
        "    self.input_mask = input_mask\n",
        "    self.segment_ids = segment_ids\n",
        "    self.start_position = start_position\n",
        "    self.end_position = end_position\n",
        "    self.is_impossible = is_impossible\n",
        "\n",
        "\n",
        "def read_squad_examples(input_file, is_training):\n",
        "  \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n",
        "  with tf.gfile.Open(input_file, \"r\") as reader:\n",
        "    input_data = json.load(reader)[\"data\"]\n",
        "\n",
        "  def is_whitespace(c):\n",
        "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  examples = []\n",
        "  for _,entry in input_data.items():\n",
        "    entry[\"paragraphs\"]\n",
        "    for _,paragraph in entry[\"paragraphs\"].items():\n",
        "      paragraph_text = paragraph[\"context\"]\n",
        "      doc_tokens = []\n",
        "      char_to_word_offset = []\n",
        "      prev_is_whitespace = True\n",
        "      for c in paragraph_text:\n",
        "        if is_whitespace(c):\n",
        "          prev_is_whitespace = True\n",
        "        else:\n",
        "          if prev_is_whitespace:\n",
        "            doc_tokens.append(c)\n",
        "          else:\n",
        "            doc_tokens[-1] += c\n",
        "          prev_is_whitespace = False\n",
        "        char_to_word_offset.append(len(doc_tokens) - 1)\n",
        "\n",
        "      for _,qa in paragraph[\"qas\"].items():\n",
        "        qas_id = qa[\"id\"]\n",
        "        question_text = qa[\"question\"]\n",
        "        start_position = None\n",
        "        end_position = None\n",
        "        orig_answer_text = None\n",
        "        is_impossible = False\n",
        "        if is_training:\n",
        "\n",
        "          if FLAGS.version_2_with_negative:\n",
        "            is_impossible = qa[\"is_impossible\"]\n",
        "          if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
        "            raise ValueError(\n",
        "                \"For training, each question should have exactly 1 answer.\")\n",
        "          if not is_impossible:\n",
        "            answer = qa[\"answers\"][\"0\"]\n",
        "            orig_answer_text = answer[\"text\"]\n",
        "            answer_offset = answer[\"answer_start\"]\n",
        "            answer_length = len(orig_answer_text)\n",
        "            start_position = char_to_word_offset[answer_offset]\n",
        "            end_position = char_to_word_offset[answer_offset + answer_length -\n",
        "                                               1]\n",
        "            # Only add answers where the text can be exactly recovered from the\n",
        "            # document. If this CAN'T happen it's likely due to weird Unicode\n",
        "            # stuff so we will just skip the example.\n",
        "            #\n",
        "            # Note that this means for training mode, every example is NOT\n",
        "            # guaranteed to be preserved.\n",
        "            actual_text = \" \".join(\n",
        "                doc_tokens[start_position:(end_position + 1)])\n",
        "            cleaned_answer_text = \" \".join(\n",
        "                tokenization.whitespace_tokenize(orig_answer_text))\n",
        "            if actual_text.find(cleaned_answer_text) == -1:\n",
        "              tf.logging.warning(\"Could not find answer: '%s' vs. '%s'\",\n",
        "                                 actual_text, cleaned_answer_text)\n",
        "              continue\n",
        "          else:\n",
        "            start_position = -1\n",
        "            end_position = -1\n",
        "            orig_answer_text = \"\"\n",
        "\n",
        "        example = SquadExample(\n",
        "            qas_id=qas_id,\n",
        "            question_text=question_text,\n",
        "            doc_tokens=doc_tokens,\n",
        "            orig_answer_text=orig_answer_text,\n",
        "            start_position=start_position,\n",
        "            end_position=end_position,\n",
        "            is_impossible=is_impossible)\n",
        "        examples.append(example)\n",
        "\n",
        "  return examples\n",
        "\n",
        "\n",
        "def convert_examples_to_features(examples, tokenizer, max_seq_length,\n",
        "                                 doc_stride, max_query_length, is_training,\n",
        "                                 output_fn):\n",
        "  \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "  unique_id = 1000000000\n",
        "\n",
        "  for (example_index, example) in enumerate(examples):\n",
        "    query_tokens = tokenizer.tokenize(example.question_text)\n",
        "\n",
        "    if len(query_tokens) > max_query_length:\n",
        "      query_tokens = query_tokens[0:max_query_length]\n",
        "\n",
        "    tok_to_orig_index = []\n",
        "    orig_to_tok_index = []\n",
        "    all_doc_tokens = []\n",
        "    for (i, token) in enumerate(example.doc_tokens):\n",
        "      orig_to_tok_index.append(len(all_doc_tokens))\n",
        "      sub_tokens = tokenizer.tokenize(token)\n",
        "      for sub_token in sub_tokens:\n",
        "        tok_to_orig_index.append(i)\n",
        "        all_doc_tokens.append(sub_token)\n",
        "\n",
        "    tok_start_position = None\n",
        "    tok_end_position = None\n",
        "    if is_training and example.is_impossible:\n",
        "      tok_start_position = -1\n",
        "      tok_end_position = -1\n",
        "    if is_training and not example.is_impossible:\n",
        "      tok_start_position = orig_to_tok_index[example.start_position]\n",
        "      if example.end_position < len(example.doc_tokens) - 1:\n",
        "        tok_end_position = orig_to_tok_index[example.end_position + 1] - 1\n",
        "      else:\n",
        "        tok_end_position = len(all_doc_tokens) - 1\n",
        "      (tok_start_position, tok_end_position) = _improve_answer_span(\n",
        "          all_doc_tokens, tok_start_position, tok_end_position, tokenizer,\n",
        "          example.orig_answer_text)\n",
        "\n",
        "    # The -3 accounts for [CLS], [SEP] and [SEP]\n",
        "    max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
        "\n",
        "    # We can have documents that are longer than the maximum sequence length.\n",
        "    # To deal with this we do a sliding window approach, where we take chunks\n",
        "    # of the up to our max length with a stride of `doc_stride`.\n",
        "    _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "        \"DocSpan\", [\"start\", \"length\"])\n",
        "    doc_spans = []\n",
        "    start_offset = 0\n",
        "    while start_offset < len(all_doc_tokens):\n",
        "      length = len(all_doc_tokens) - start_offset\n",
        "      if length > max_tokens_for_doc:\n",
        "        length = max_tokens_for_doc\n",
        "      doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
        "      if start_offset + length == len(all_doc_tokens):\n",
        "        break\n",
        "      start_offset += min(length, doc_stride)\n",
        "\n",
        "    for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
        "      tokens = []\n",
        "      token_to_orig_map = {}\n",
        "      token_is_max_context = {}\n",
        "      segment_ids = []\n",
        "      tokens.append(\"[CLS]\")\n",
        "      segment_ids.append(0)\n",
        "      for token in query_tokens:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "      tokens.append(\"[SEP]\")\n",
        "      segment_ids.append(0)\n",
        "\n",
        "      for i in range(doc_span.length):\n",
        "        split_token_index = doc_span.start + i\n",
        "        token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
        "\n",
        "        is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
        "                                               split_token_index)\n",
        "        token_is_max_context[len(tokens)] = is_max_context\n",
        "        tokens.append(all_doc_tokens[split_token_index])\n",
        "        segment_ids.append(1)\n",
        "      tokens.append(\"[SEP]\")\n",
        "      segment_ids.append(1)\n",
        "\n",
        "      input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "      # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "      # tokens are attended to.\n",
        "      input_mask = [1] * len(input_ids)\n",
        "\n",
        "      # Zero-pad up to the sequence length.\n",
        "      while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "      assert len(input_ids) == max_seq_length\n",
        "      assert len(input_mask) == max_seq_length\n",
        "      assert len(segment_ids) == max_seq_length\n",
        "\n",
        "      start_position = None\n",
        "      end_position = None\n",
        "      if is_training and not example.is_impossible:\n",
        "        # For training, if our document chunk does not contain an annotation\n",
        "        # we throw it out, since there is nothing to predict.\n",
        "        doc_start = doc_span.start\n",
        "        doc_end = doc_span.start + doc_span.length - 1\n",
        "        out_of_span = False\n",
        "        if not (tok_start_position >= doc_start and\n",
        "                tok_end_position <= doc_end):\n",
        "          out_of_span = True\n",
        "        if out_of_span:\n",
        "          start_position = 0\n",
        "          end_position = 0\n",
        "        else:\n",
        "          doc_offset = len(query_tokens) + 2\n",
        "          start_position = tok_start_position - doc_start + doc_offset\n",
        "          end_position = tok_end_position - doc_start + doc_offset\n",
        "\n",
        "      if is_training and example.is_impossible:\n",
        "        start_position = 0\n",
        "        end_position = 0\n",
        "\n",
        "      if example_index < 20:\n",
        "        tf.logging.info(\"*** Example ***\")\n",
        "        tf.logging.info(\"unique_id: %s\" % (unique_id))\n",
        "        tf.logging.info(\"example_index: %s\" % (example_index))\n",
        "        tf.logging.info(\"doc_span_index: %s\" % (doc_span_index))\n",
        "        tf.logging.info(\"tokens: %s\" % \" \".join(\n",
        "            [tokenization.printable_text(x) for x in tokens]))\n",
        "        tf.logging.info(\"token_to_orig_map: %s\" % \" \".join(\n",
        "            [\"%d:%d\" % (x, y) for (x, y) in six.iteritems(token_to_orig_map)]))\n",
        "        tf.logging.info(\"token_is_max_context: %s\" % \" \".join([\n",
        "            \"%d:%s\" % (x, y) for (x, y) in six.iteritems(token_is_max_context)\n",
        "        ]))\n",
        "        tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "        tf.logging.info(\n",
        "            \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "        tf.logging.info(\n",
        "            \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "        if is_training and example.is_impossible:\n",
        "          tf.logging.info(\"impossible example\")\n",
        "        if is_training and not example.is_impossible:\n",
        "          answer_text = \" \".join(tokens[start_position:(end_position + 1)])\n",
        "          tf.logging.info(\"start_position: %d\" % (start_position))\n",
        "          tf.logging.info(\"end_position: %d\" % (end_position))\n",
        "          tf.logging.info(\n",
        "              \"answer: %s\" % (tokenization.printable_text(answer_text)))\n",
        "\n",
        "      feature = InputFeatures(\n",
        "          unique_id=unique_id,\n",
        "          example_index=example_index,\n",
        "          doc_span_index=doc_span_index,\n",
        "          tokens=tokens,\n",
        "          token_to_orig_map=token_to_orig_map,\n",
        "          token_is_max_context=token_is_max_context,\n",
        "          input_ids=input_ids,\n",
        "          input_mask=input_mask,\n",
        "          segment_ids=segment_ids,\n",
        "          start_position=start_position,\n",
        "          end_position=end_position,\n",
        "          is_impossible=example.is_impossible)\n",
        "\n",
        "      # Run callback\n",
        "      output_fn(feature)\n",
        "\n",
        "      unique_id += 1\n",
        "\n",
        "\n",
        "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n",
        "                         orig_answer_text):\n",
        "  \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n",
        "\n",
        "  # The SQuAD annotations are character based. We first project them to\n",
        "  # whitespace-tokenized words. But then after WordPiece tokenization, we can\n",
        "  # often find a \"better match\". For example:\n",
        "  #\n",
        "  #   Question: What year was John Smith born?\n",
        "  #   Context: The leader was John Smith (1895-1943).\n",
        "  #   Answer: 1895\n",
        "  #\n",
        "  # The original whitespace-tokenized answer will be \"(1895-1943).\". However\n",
        "  # after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match\n",
        "  # the exact answer, 1895.\n",
        "  #\n",
        "  # However, this is not always possible. Consider the following:\n",
        "  #\n",
        "  #   Question: What country is the top exporter of electornics?\n",
        "  #   Context: The Japanese electronics industry is the lagest in the world.\n",
        "  #   Answer: Japan\n",
        "  #\n",
        "  # In this case, the annotator chose \"Japan\" as a character sub-span of\n",
        "  # the word \"Japanese\". Since our WordPiece tokenizer does not split\n",
        "  # \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare\n",
        "  # in SQuAD, but does happen.\n",
        "  tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n",
        "\n",
        "  for new_start in range(input_start, input_end + 1):\n",
        "    for new_end in range(input_end, new_start - 1, -1):\n",
        "      text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n",
        "      if text_span == tok_answer_text:\n",
        "        return (new_start, new_end)\n",
        "\n",
        "  return (input_start, input_end)\n",
        "\n",
        "\n",
        "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
        "  \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
        "\n",
        "  # Because of the sliding window approach taken to scoring documents, a single\n",
        "  # token can appear in multiple documents. E.g.\n",
        "  #  Doc: the man went to the store and bought a gallon of milk\n",
        "  #  Span A: the man went to the\n",
        "  #  Span B: to the store and bought\n",
        "  #  Span C: and bought a gallon of\n",
        "  #  ...\n",
        "  #\n",
        "  # Now the word 'bought' will have two scores from spans B and C. We only\n",
        "  # want to consider the score with \"maximum context\", which we define as\n",
        "  # the *minimum* of its left and right context (the *sum* of left and\n",
        "  # right context will always be the same, of course).\n",
        "  #\n",
        "  # In the example the maximum context for 'bought' would be span C since\n",
        "  # it has 1 left context and 3 right context, while span B has 4 left context\n",
        "  # and 0 right context.\n",
        "  best_score = None\n",
        "  best_span_index = None\n",
        "  for (span_index, doc_span) in enumerate(doc_spans):\n",
        "    end = doc_span.start + doc_span.length - 1\n",
        "    if position < doc_span.start:\n",
        "      continue\n",
        "    if position > end:\n",
        "      continue\n",
        "    num_left_context = position - doc_span.start\n",
        "    num_right_context = end - position\n",
        "    score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
        "    if best_score is None or score > best_score:\n",
        "      best_score = score\n",
        "      best_span_index = span_index\n",
        "\n",
        "  return cur_span_index == best_span_index\n",
        "\n",
        "\n",
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 use_one_hot_embeddings):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  model = modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "  final_hidden = model.get_sequence_output()\n",
        "\n",
        "  final_hidden_shape = modeling.get_shape_list(final_hidden, expected_rank=3)\n",
        "  batch_size = final_hidden_shape[0]\n",
        "  seq_length = final_hidden_shape[1]\n",
        "  hidden_size = final_hidden_shape[2]\n",
        "\n",
        "  output_weights = tf.get_variable(\n",
        "      \"cls/squad/output_weights\", [2, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"cls/squad/output_bias\", [2], initializer=tf.zeros_initializer())\n",
        "\n",
        "  final_hidden_matrix = tf.reshape(final_hidden,\n",
        "                                   [batch_size * seq_length, hidden_size])\n",
        "  logits = tf.matmul(final_hidden_matrix, output_weights, transpose_b=True)\n",
        "  logits = tf.nn.bias_add(logits, output_bias)\n",
        "\n",
        "  logits = tf.reshape(logits, [batch_size, seq_length, 2])\n",
        "  logits = tf.transpose(logits, [2, 0, 1])\n",
        "\n",
        "  unstacked_logits = tf.unstack(logits, axis=0)\n",
        "\n",
        "  (start_logits, end_logits) = (unstacked_logits[0], unstacked_logits[1])\n",
        "\n",
        "  return (start_logits, end_logits)\n",
        "\n",
        "\n",
        "def model_fn_builder(bert_config, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    unique_ids = features[\"unique_ids\"]\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (start_logits, end_logits) = create_model(\n",
        "        bert_config=bert_config,\n",
        "        is_training=is_training,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      seq_length = modeling.get_shape_list(input_ids)[1]\n",
        "\n",
        "      def compute_loss(logits, positions):\n",
        "        one_hot_positions = tf.one_hot(\n",
        "            positions, depth=seq_length, dtype=tf.float32)\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "        loss = -tf.reduce_mean(\n",
        "            tf.reduce_sum(one_hot_positions * log_probs, axis=-1))\n",
        "        return loss\n",
        "\n",
        "      start_positions = features[\"start_positions\"]\n",
        "      end_positions = features[\"end_positions\"]\n",
        "\n",
        "      start_loss = compute_loss(start_logits, start_positions)\n",
        "      end_loss = compute_loss(end_logits, end_positions)\n",
        "\n",
        "      total_loss = (start_loss + end_loss) / 2.0\n",
        "\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "      predictions = {\n",
        "          \"unique_ids\": unique_ids,\n",
        "          \"start_logits\": start_logits,\n",
        "          \"end_logits\": end_logits,\n",
        "      }\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          \"Only TRAIN and PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn\n",
        "\n",
        "\n",
        "def input_fn_builder(input_file, seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  name_to_features = {\n",
        "      \"unique_ids\": tf.FixedLenFeature([], tf.int64),\n",
        "      \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "      \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "      \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "  }\n",
        "\n",
        "  if is_training:\n",
        "    name_to_features[\"start_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
        "    name_to_features[\"end_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
        "\n",
        "  def _decode_record(record, name_to_features):\n",
        "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "    example = tf.parse_single_example(record, name_to_features)\n",
        "\n",
        "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
        "    # So cast all int64 to int32.\n",
        "    for name in list(example.keys()):\n",
        "      t = example[name]\n",
        "      if t.dtype == tf.int64:\n",
        "        t = tf.to_int32(t)\n",
        "      example[name] = t\n",
        "\n",
        "    return example\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    # For training, we want a lot of parallel reading and shuffling.\n",
        "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
        "    d = tf.data.TFRecordDataset(input_file)\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.apply(\n",
        "        tf.contrib.data.map_and_batch(\n",
        "            lambda record: _decode_record(record, name_to_features),\n",
        "            batch_size=batch_size,\n",
        "            drop_remainder=drop_remainder))\n",
        "\n",
        "    return d\n",
        "\n",
        "  return input_fn\n",
        "\n",
        "\n",
        "RawResult = collections.namedtuple(\"RawResult\",\n",
        "                                   [\"unique_id\", \"start_logits\", \"end_logits\"])\n",
        "\n",
        "\n",
        "def write_predictions(all_examples, all_features, all_results, n_best_size,\n",
        "                      max_answer_length, do_lower_case, output_prediction_file,\n",
        "                      output_nbest_file, output_null_log_odds_file):\n",
        "  \"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"\n",
        "  tf.logging.info(\"Writing predictions to: %s\" % (output_prediction_file))\n",
        "  tf.logging.info(\"Writing nbest to: %s\" % (output_nbest_file))\n",
        "\n",
        "  example_index_to_features = collections.defaultdict(list)\n",
        "  for feature in all_features:\n",
        "    example_index_to_features[feature.example_index].append(feature)\n",
        "\n",
        "  unique_id_to_result = {}\n",
        "  for result in all_results:\n",
        "    unique_id_to_result[result.unique_id] = result\n",
        "\n",
        "  _PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "      \"PrelimPrediction\",\n",
        "      [\"feature_index\", \"start_index\", \"end_index\", \"start_logit\", \"end_logit\"])\n",
        "\n",
        "  all_predictions = collections.OrderedDict()\n",
        "  all_nbest_json = collections.OrderedDict()\n",
        "  scores_diff_json = collections.OrderedDict()\n",
        "\n",
        "  for (example_index, example) in enumerate(all_examples):\n",
        "    features = example_index_to_features[example_index]\n",
        "\n",
        "    prelim_predictions = []\n",
        "    # keep track of the minimum score of null start+end of position 0\n",
        "    score_null = 1000000  # large and positive\n",
        "    min_null_feature_index = 0  # the paragraph slice with min mull score\n",
        "    null_start_logit = 0  # the start logit at the slice with min null score\n",
        "    null_end_logit = 0  # the end logit at the slice with min null score\n",
        "    for (feature_index, feature) in enumerate(features):\n",
        "      result = unique_id_to_result[feature.unique_id]\n",
        "      start_indexes = _get_best_indexes(result.start_logits, n_best_size)\n",
        "      end_indexes = _get_best_indexes(result.end_logits, n_best_size)\n",
        "      # if we could have irrelevant answers, get the min score of irrelevant\n",
        "      if FLAGS.version_2_with_negative:\n",
        "        feature_null_score = result.start_logits[0] + result.end_logits[0]\n",
        "        if feature_null_score < score_null:\n",
        "          score_null = feature_null_score\n",
        "          min_null_feature_index = feature_index\n",
        "          null_start_logit = result.start_logits[0]\n",
        "          null_end_logit = result.end_logits[0]\n",
        "      for start_index in start_indexes:\n",
        "        for end_index in end_indexes:\n",
        "          # We could hypothetically create invalid predictions, e.g., predict\n",
        "          # that the start of the span is in the question. We throw out all\n",
        "          # invalid predictions.\n",
        "          if start_index >= len(feature.tokens):\n",
        "            continue\n",
        "          if end_index >= len(feature.tokens):\n",
        "            continue\n",
        "          if start_index not in feature.token_to_orig_map:\n",
        "            continue\n",
        "          if end_index not in feature.token_to_orig_map:\n",
        "            continue\n",
        "          if not feature.token_is_max_context.get(start_index, False):\n",
        "            continue\n",
        "          if end_index < start_index:\n",
        "            continue\n",
        "          length = end_index - start_index + 1\n",
        "          if length > max_answer_length:\n",
        "            continue\n",
        "          prelim_predictions.append(\n",
        "              _PrelimPrediction(\n",
        "                  feature_index=feature_index,\n",
        "                  start_index=start_index,\n",
        "                  end_index=end_index,\n",
        "                  start_logit=result.start_logits[start_index],\n",
        "                  end_logit=result.end_logits[end_index]))\n",
        "\n",
        "    if FLAGS.version_2_with_negative:\n",
        "      prelim_predictions.append(\n",
        "          _PrelimPrediction(\n",
        "              feature_index=min_null_feature_index,\n",
        "              start_index=0,\n",
        "              end_index=0,\n",
        "              start_logit=null_start_logit,\n",
        "              end_logit=null_end_logit))\n",
        "    prelim_predictions = sorted(\n",
        "        prelim_predictions,\n",
        "        key=lambda x: (x.start_logit + x.end_logit),\n",
        "        reverse=True)\n",
        "\n",
        "    _NbestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "        \"NbestPrediction\", [\"text\", \"start_logit\", \"end_logit\"])\n",
        "\n",
        "    seen_predictions = {}\n",
        "    nbest = []\n",
        "    for pred in prelim_predictions:\n",
        "      if len(nbest) >= n_best_size:\n",
        "        break\n",
        "      feature = features[pred.feature_index]\n",
        "      if pred.start_index > 0:  # this is a non-null prediction\n",
        "        tok_tokens = feature.tokens[pred.start_index:(pred.end_index + 1)]\n",
        "        orig_doc_start = feature.token_to_orig_map[pred.start_index]\n",
        "        orig_doc_end = feature.token_to_orig_map[pred.end_index]\n",
        "        orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + 1)]\n",
        "        tok_text = \" \".join(tok_tokens)\n",
        "\n",
        "        # De-tokenize WordPieces that have been split off.\n",
        "        tok_text = tok_text.replace(\" ##\", \"\")\n",
        "        tok_text = tok_text.replace(\"##\", \"\")\n",
        "\n",
        "        # Clean whitespace\n",
        "        tok_text = tok_text.strip()\n",
        "        tok_text = \" \".join(tok_text.split())\n",
        "        orig_text = \" \".join(orig_tokens)\n",
        "\n",
        "        final_text = get_final_text(tok_text, orig_text, do_lower_case)\n",
        "        if final_text in seen_predictions:\n",
        "          continue\n",
        "\n",
        "        seen_predictions[final_text] = True\n",
        "      else:\n",
        "        final_text = \"\"\n",
        "        seen_predictions[final_text] = True\n",
        "\n",
        "      nbest.append(\n",
        "          _NbestPrediction(\n",
        "              text=final_text,\n",
        "              start_logit=pred.start_logit,\n",
        "              end_logit=pred.end_logit))\n",
        "\n",
        "    # if we didn't inlude the empty option in the n-best, inlcude it\n",
        "    if FLAGS.version_2_with_negative:\n",
        "      if \"\" not in seen_predictions:\n",
        "        nbest.append(\n",
        "            _NbestPrediction(\n",
        "                text=\"\", start_logit=null_start_logit,\n",
        "                end_logit=null_end_logit))\n",
        "    # In very rare edge cases we could have no valid predictions. So we\n",
        "    # just create a nonce prediction in this case to avoid failure.\n",
        "    if not nbest:\n",
        "      nbest.append(\n",
        "          _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n",
        "\n",
        "    assert len(nbest) >= 1\n",
        "\n",
        "    total_scores = []\n",
        "    best_non_null_entry = None\n",
        "    for entry in nbest:\n",
        "      total_scores.append(entry.start_logit + entry.end_logit)\n",
        "      if not best_non_null_entry:\n",
        "        if entry.text:\n",
        "          best_non_null_entry = entry\n",
        "\n",
        "    probs = _compute_softmax(total_scores)\n",
        "\n",
        "    nbest_json = []\n",
        "    for (i, entry) in enumerate(nbest):\n",
        "      output = collections.OrderedDict()\n",
        "      output[\"text\"] = entry.text\n",
        "      output[\"probability\"] = probs[i]\n",
        "      output[\"start_logit\"] = entry.start_logit\n",
        "      output[\"end_logit\"] = entry.end_logit\n",
        "      nbest_json.append(output)\n",
        "\n",
        "    assert len(nbest_json) >= 1\n",
        "\n",
        "    if not FLAGS.version_2_with_negative:\n",
        "      all_predictions[example.qas_id] = nbest_json[0][\"text\"]\n",
        "    else:\n",
        "      # predict \"\" iff the null score - the score of best non-null > threshold\n",
        "      score_diff = score_null - best_non_null_entry.start_logit - (\n",
        "          best_non_null_entry.end_logit)\n",
        "      scores_diff_json[example.qas_id] = score_diff\n",
        "      if score_diff > FLAGS.null_score_diff_threshold:\n",
        "        all_predictions[example.qas_id] = \"\"\n",
        "      else:\n",
        "        all_predictions[example.qas_id] = best_non_null_entry.text\n",
        "\n",
        "    all_nbest_json[example.qas_id] = nbest_json\n",
        "\n",
        "  with tf.gfile.GFile(output_prediction_file, \"w\") as writer:\n",
        "    writer.write(json.dumps(all_predictions, indent=4) + \"\\n\")\n",
        "\n",
        "  with tf.gfile.GFile(output_nbest_file, \"w\") as writer:\n",
        "    writer.write(json.dumps(all_nbest_json, indent=4) + \"\\n\")\n",
        "\n",
        "  if FLAGS.version_2_with_negative:\n",
        "    with tf.gfile.GFile(output_null_log_odds_file, \"w\") as writer:\n",
        "      writer.write(json.dumps(scores_diff_json, indent=4) + \"\\n\")\n",
        "\n",
        "\n",
        "def get_final_text(pred_text, orig_text, do_lower_case):\n",
        "  \"\"\"Project the tokenized prediction back to the original text.\"\"\"\n",
        "\n",
        "  # When we created the data, we kept track of the alignment between original\n",
        "  # (whitespace tokenized) tokens and our WordPiece tokenized tokens. So\n",
        "  # now `orig_text` contains the span of our original text corresponding to the\n",
        "  # span that we predicted.\n",
        "  #\n",
        "  # However, `orig_text` may contain extra characters that we don't want in\n",
        "  # our prediction.\n",
        "  #\n",
        "  # For example, let's say:\n",
        "  #   pred_text = steve smith\n",
        "  #   orig_text = Steve Smith's\n",
        "  #\n",
        "  # We don't want to return `orig_text` because it contains the extra \"'s\".\n",
        "  #\n",
        "  # We don't want to return `pred_text` because it's already been normalized\n",
        "  # (the SQuAD eval script also does punctuation stripping/lower casing but\n",
        "  # our tokenizer does additional normalization like stripping accent\n",
        "  # characters).\n",
        "  #\n",
        "  # What we really want to return is \"Steve Smith\".\n",
        "  #\n",
        "  # Therefore, we have to apply a semi-complicated alignment heruistic between\n",
        "  # `pred_text` and `orig_text` to get a character-to-charcter alignment. This\n",
        "  # can fail in certain cases in which case we just return `orig_text`.\n",
        "\n",
        "  def _strip_spaces(text):\n",
        "    ns_chars = []\n",
        "    ns_to_s_map = collections.OrderedDict()\n",
        "    for (i, c) in enumerate(text):\n",
        "      if c == \" \":\n",
        "        continue\n",
        "      ns_to_s_map[len(ns_chars)] = i\n",
        "      ns_chars.append(c)\n",
        "    ns_text = \"\".join(ns_chars)\n",
        "    return (ns_text, ns_to_s_map)\n",
        "\n",
        "  # We first tokenize `orig_text`, strip whitespace from the result\n",
        "  # and `pred_text`, and check if they are the same length. If they are\n",
        "  # NOT the same length, the heuristic has failed. If they are the same\n",
        "  # length, we assume the characters are one-to-one aligned.\n",
        "  tokenizer = tokenization.BasicTokenizer(do_lower_case=do_lower_case)\n",
        "\n",
        "  tok_text = \" \".join(tokenizer.tokenize(orig_text))\n",
        "\n",
        "  start_position = tok_text.find(pred_text)\n",
        "  if start_position == -1:\n",
        "    if FLAGS.verbose_logging:\n",
        "      tf.logging.info(\n",
        "          \"Unable to find text: '%s' in '%s'\" % (pred_text, orig_text))\n",
        "    return orig_text\n",
        "  end_position = start_position + len(pred_text) - 1\n",
        "\n",
        "  (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text)\n",
        "  (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text)\n",
        "\n",
        "  if len(orig_ns_text) != len(tok_ns_text):\n",
        "    if FLAGS.verbose_logging:\n",
        "      tf.logging.info(\"Length not equal after stripping spaces: '%s' vs '%s'\",\n",
        "                      orig_ns_text, tok_ns_text)\n",
        "    return orig_text\n",
        "\n",
        "  # We then project the characters in `pred_text` back to `orig_text` using\n",
        "  # the character-to-character alignment.\n",
        "  tok_s_to_ns_map = {}\n",
        "  for (i, tok_index) in six.iteritems(tok_ns_to_s_map):\n",
        "    tok_s_to_ns_map[tok_index] = i\n",
        "\n",
        "  orig_start_position = None\n",
        "  if start_position in tok_s_to_ns_map:\n",
        "    ns_start_position = tok_s_to_ns_map[start_position]\n",
        "    if ns_start_position in orig_ns_to_s_map:\n",
        "      orig_start_position = orig_ns_to_s_map[ns_start_position]\n",
        "\n",
        "  if orig_start_position is None:\n",
        "    if FLAGS.verbose_logging:\n",
        "      tf.logging.info(\"Couldn't map start position\")\n",
        "    return orig_text\n",
        "\n",
        "  orig_end_position = None\n",
        "  if end_position in tok_s_to_ns_map:\n",
        "    ns_end_position = tok_s_to_ns_map[end_position]\n",
        "    if ns_end_position in orig_ns_to_s_map:\n",
        "      orig_end_position = orig_ns_to_s_map[ns_end_position]\n",
        "\n",
        "  if orig_end_position is None:\n",
        "    if FLAGS.verbose_logging:\n",
        "      tf.logging.info(\"Couldn't map end position\")\n",
        "    return orig_text\n",
        "\n",
        "  output_text = orig_text[orig_start_position:(orig_end_position + 1)]\n",
        "  return output_text\n",
        "\n",
        "\n",
        "def _get_best_indexes(logits, n_best_size):\n",
        "  \"\"\"Get the n-best logits from a list.\"\"\"\n",
        "  index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  best_indexes = []\n",
        "  for i in range(len(index_and_score)):\n",
        "    if i >= n_best_size:\n",
        "      break\n",
        "    best_indexes.append(index_and_score[i][0])\n",
        "  return best_indexes\n",
        "\n",
        "\n",
        "def _compute_softmax(scores):\n",
        "  \"\"\"Compute softmax probability over raw logits.\"\"\"\n",
        "  if not scores:\n",
        "    return []\n",
        "\n",
        "  max_score = None\n",
        "  for score in scores:\n",
        "    if max_score is None or score > max_score:\n",
        "      max_score = score\n",
        "\n",
        "  exp_scores = []\n",
        "  total_sum = 0.0\n",
        "  for score in scores:\n",
        "    x = math.exp(score - max_score)\n",
        "    exp_scores.append(x)\n",
        "    total_sum += x\n",
        "\n",
        "  probs = []\n",
        "  for score in exp_scores:\n",
        "    probs.append(score / total_sum)\n",
        "  return probs\n",
        "\n",
        "\n",
        "class FeatureWriter(object):\n",
        "  \"\"\"Writes InputFeature to TF example file.\"\"\"\n",
        "\n",
        "  def __init__(self, filename, is_training):\n",
        "    self.filename = filename\n",
        "    self.is_training = is_training\n",
        "    self.num_features = 0\n",
        "    self._writer = tf.python_io.TFRecordWriter(filename)\n",
        "\n",
        "  def process_feature(self, feature):\n",
        "    \"\"\"Write a InputFeature to the TFRecordWriter as a tf.train.Example.\"\"\"\n",
        "    self.num_features += 1\n",
        "\n",
        "    def create_int_feature(values):\n",
        "      feature = tf.train.Feature(\n",
        "          int64_list=tf.train.Int64List(value=list(values)))\n",
        "      return feature\n",
        "\n",
        "    features = collections.OrderedDict()\n",
        "    features[\"unique_ids\"] = create_int_feature([feature.unique_id])\n",
        "    features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
        "    features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
        "    features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
        "\n",
        "    if self.is_training:\n",
        "      features[\"start_positions\"] = create_int_feature([feature.start_position])\n",
        "      features[\"end_positions\"] = create_int_feature([feature.end_position])\n",
        "      impossible = 0\n",
        "      if feature.is_impossible:\n",
        "        impossible = 1\n",
        "      features[\"is_impossible\"] = create_int_feature([impossible])\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
        "    self._writer.write(tf_example.SerializeToString())\n",
        "\n",
        "  def close(self):\n",
        "    self._writer.close()\n",
        "\n",
        "\n",
        "def validate_flags_or_throw(bert_config):\n",
        "  \"\"\"Validate the input FLAGS or throw an exception.\"\"\"\n",
        "  if not FLAGS.do_train and not FLAGS.do_predict:\n",
        "    raise ValueError(\"At least one of `do_train` or `do_predict` must be True.\")\n",
        "\n",
        "  if FLAGS.do_train:\n",
        "    if not FLAGS.train_file:\n",
        "      raise ValueError(\n",
        "          \"If `do_train` is True, then `train_file` must be specified.\")\n",
        "  if FLAGS.do_predict:\n",
        "    if not FLAGS.predict_file:\n",
        "      raise ValueError(\n",
        "          \"If `do_predict` is True, then `predict_file` must be specified.\")\n",
        "\n",
        "  if FLAGS.max_seq_length > bert_config.max_position_embeddings:\n",
        "    raise ValueError(\n",
        "        \"Cannot use sequence length %d because the BERT model \"\n",
        "        \"was only trained up to sequence length %d\" %\n",
        "        (FLAGS.max_seq_length, bert_config.max_position_embeddings))\n",
        "\n",
        "  if FLAGS.max_seq_length <= FLAGS.max_query_length + 3:\n",
        "    raise ValueError(\n",
        "        \"The max_seq_length (%d) must be greater than max_query_length \"\n",
        "        \"(%d) + 3\" % (FLAGS.max_seq_length, FLAGS.max_query_length))\n",
        "\n",
        "\n",
        "def main(_):\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "  bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
        "\n",
        "  validate_flags_or_throw(bert_config)\n",
        "\n",
        "  tf.gfile.MakeDirs(FLAGS.output_dir)\n",
        "\n",
        "  tokenizer = tokenization.FullTokenizer(\n",
        "      vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
        "\n",
        "  tpu_cluster_resolver = None\n",
        "  if FLAGS.use_tpu and FLAGS.tpu_name:\n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "        FLAGS.tpu_name, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)\n",
        "\n",
        "  is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      master=FLAGS.master,\n",
        "      model_dir=FLAGS.output_dir,\n",
        "      save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=FLAGS.iterations_per_loop,\n",
        "          num_shards=FLAGS.num_tpu_cores,\n",
        "          per_host_input_for_training=is_per_host))\n",
        "\n",
        "  train_examples = None\n",
        "  num_train_steps = None\n",
        "  num_warmup_steps = None\n",
        "  if FLAGS.do_train:\n",
        "    train_examples = read_squad_examples(\n",
        "        input_file=FLAGS.train_file, is_training=True)\n",
        "    num_train_steps = int(\n",
        "        len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)\n",
        "    num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)\n",
        "\n",
        "    # Pre-shuffle the input to avoid having to make a very large shuffle\n",
        "    # buffer in in the `input_fn`.\n",
        "    rng = random.Random(12345)\n",
        "    rng.shuffle(train_examples)\n",
        "\n",
        "  model_fn = model_fn_builder(\n",
        "      bert_config=bert_config,\n",
        "      init_checkpoint=FLAGS.init_checkpoint,\n",
        "      learning_rate=FLAGS.learning_rate,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      use_tpu=FLAGS.use_tpu,\n",
        "      use_one_hot_embeddings=FLAGS.use_tpu)\n",
        "\n",
        "  # If TPU is not available, this will fall back to normal Estimator on CPU\n",
        "  # or GPU.\n",
        "  estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=FLAGS.use_tpu,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      train_batch_size=FLAGS.train_batch_size,\n",
        "      predict_batch_size=FLAGS.predict_batch_size)\n",
        "\n",
        "  if FLAGS.do_train:\n",
        "    # We write to a temporary file to avoid storing very large constant tensors\n",
        "    # in memory.\n",
        "    train_writer = FeatureWriter(\n",
        "        filename=os.path.join(FLAGS.output_dir, \"train.tf_record\"),\n",
        "        is_training=True)\n",
        "    convert_examples_to_features(\n",
        "        examples=train_examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=FLAGS.max_seq_length,\n",
        "        doc_stride=FLAGS.doc_stride,\n",
        "        max_query_length=FLAGS.max_query_length,\n",
        "        is_training=True,\n",
        "        output_fn=train_writer.process_feature)\n",
        "    train_writer.close()\n",
        "\n",
        "    tf.logging.info(\"***** Running training *****\")\n",
        "    tf.logging.info(\"  Num orig examples = %d\", len(train_examples))\n",
        "    tf.logging.info(\"  Num split examples = %d\", train_writer.num_features)\n",
        "    tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\n",
        "    tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "    del train_examples\n",
        "\n",
        "    train_input_fn = input_fn_builder(\n",
        "        input_file=train_writer.filename,\n",
        "        seq_length=FLAGS.max_seq_length,\n",
        "        is_training=True,\n",
        "        drop_remainder=True)\n",
        "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "\n",
        "  if FLAGS.do_predict:\n",
        "    eval_examples = read_squad_examples(\n",
        "        input_file=FLAGS.predict_file, is_training=False)\n",
        "\n",
        "    eval_writer = FeatureWriter(\n",
        "        filename=os.path.join(FLAGS.output_dir, \"eval.tf_record\"),\n",
        "        is_training=False)\n",
        "    eval_features = []\n",
        "\n",
        "    def append_feature(feature):\n",
        "      eval_features.append(feature)\n",
        "      eval_writer.process_feature(feature)\n",
        "\n",
        "    convert_examples_to_features(\n",
        "        examples=eval_examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=FLAGS.max_seq_length,\n",
        "        doc_stride=FLAGS.doc_stride,\n",
        "        max_query_length=FLAGS.max_query_length,\n",
        "        is_training=False,\n",
        "        output_fn=append_feature)\n",
        "    eval_writer.close()\n",
        "\n",
        "    tf.logging.info(\"***** Running predictions *****\")\n",
        "    tf.logging.info(\"  Num orig examples = %d\", len(eval_examples))\n",
        "    tf.logging.info(\"  Num split examples = %d\", len(eval_features))\n",
        "    tf.logging.info(\"  Batch size = %d\", FLAGS.predict_batch_size)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    predict_input_fn = input_fn_builder(\n",
        "        input_file=eval_writer.filename,\n",
        "        seq_length=FLAGS.max_seq_length,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    # If running eval on the TPU, you will need to specify the number of\n",
        "    # steps.\n",
        "    all_results = []\n",
        "    for result in estimator.predict(\n",
        "        predict_input_fn, yield_single_examples=True):\n",
        "      if len(all_results) % 1000 == 0:\n",
        "        tf.logging.info(\"Processing example: %d\" % (len(all_results)))\n",
        "      unique_id = int(result[\"unique_ids\"])\n",
        "      start_logits = [float(x) for x in result[\"start_logits\"].flat]\n",
        "      end_logits = [float(x) for x in result[\"end_logits\"].flat]\n",
        "      all_results.append(\n",
        "          RawResult(\n",
        "              unique_id=unique_id,\n",
        "              start_logits=start_logits,\n",
        "              end_logits=end_logits))\n",
        "\n",
        "    output_prediction_file = os.path.join(FLAGS.output_dir, \"predictions.json\")\n",
        "    output_nbest_file = os.path.join(FLAGS.output_dir, \"nbest_predictions.json\")\n",
        "    output_null_log_odds_file = os.path.join(FLAGS.output_dir, \"null_odds.json\")\n",
        "\n",
        "    write_predictions(eval_examples, eval_features, all_results,\n",
        "                      FLAGS.n_best_size, FLAGS.max_answer_length,\n",
        "                      FLAGS.do_lower_case, output_prediction_file,\n",
        "                      output_nbest_file, output_null_log_odds_file)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  flags.mark_flag_as_required(\"vocab_file\")\n",
        "  flags.mark_flag_as_required(\"bert_config_file\")\n",
        "  flags.mark_flag_as_required(\"output_dir\")\n",
        "  tf.app.run()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Could not find answer: 'The State' vs. 'Oyster Bay'\n",
            "WARNING:tensorflow:Could not find answer: 'The State University of New York at Stony' vs. 'State University College on Long Island'\n",
            "WARNING:tensorflow:Could not find answer: 'The State University' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'The' vs. 'SUNY'\n",
            "WARNING:tensorflow:Could not find answer: 'The university's' vs. 'Long Island'\n",
            "WARNING:tensorflow:Could not find answer: 'The university's health science' vs. 'Brookhaven National Laboratory'\n",
            "WARNING:tensorflow:Could not find answer: 'The university's health science and medical' vs. 'the United States Department of Energy'\n",
            "WARNING:tensorflow:Could not find answer: 'The university's health science' vs. 'a Research & Development Park'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook' vs. 'Long Island'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook's intercollegiate' vs. 'Division I of the NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook's intercollegiate' vs. 'the America East Conference'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook's intercollegiate athletic' vs. 'the Colonial Athletic Association'\n",
            "WARNING:tensorflow:Could not find answer: 'Coe Hall on' vs. 'Oyster Bay'\n",
            "WARNING:tensorflow:Could not find answer: 'Coe Hall on the original Oyster' vs. 'State University of New York'\n",
            "WARNING:tensorflow:Could not find answer: 'Coe Hall on' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'Coe Hall' vs. 'Oyster'\n",
            "WARNING:tensorflow:Could not find answer: 'Coe Hall on the original Oyster Bay campus' vs. 'the State University College on Long Island'\n",
            "WARNING:tensorflow:Could not find answer: 'Coe Hall' vs. 'New York'\n",
            "WARNING:tensorflow:Could not find answer: 'Coe Hall on' vs. 'New York's'\n",
            "WARNING:tensorflow:Could not find answer: '1961' vs. 'Lee'\n",
            "WARNING:tensorflow:Could not find answer: 'Ward Melville,' vs. 'Three Village'\n",
            "WARNING:tensorflow:Could not find answer: 'Ward Melville,' vs. 'Suffolk County'\n",
            "WARNING:tensorflow:Could not find answer: 'Ward Melville, a philanthropist' vs. 'the Stony Brook Union'\n",
            "WARNING:tensorflow:Could not find answer: 'Ward Melville, a philanthropist' vs. 'Frank Melville Jr.'\n",
            "WARNING:tensorflow:Could not find answer: 'Ward Melville,' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'Ward Melville, a philanthropist' vs. 'the Health Science Center'\n",
            "WARNING:tensorflow:Could not find answer: 'Ward Melville,' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'Ward Melville,' vs. 'Hospital'\n",
            "WARNING:tensorflow:Could not find answer: 'Ward Melville,' vs. 'Albany'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s affirmed Stony Brook's success' vs. 'Association of American Universities'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s affirmed' vs. 'North America'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/absl/flags/_validators.py:358: UserWarning: Flag --vocab_file has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
            "  'command line!' % flag_name)\n",
            "/usr/local/lib/python3.6/dist-packages/absl/flags/_validators.py:358: UserWarning: Flag --bert_config_file has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
            "  'command line!' % flag_name)\n",
            "/usr/local/lib/python3.6/dist-packages/absl/flags/_validators.py:358: UserWarning: Flag --output_dir has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
            "  'command line!' % flag_name)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Could not find answer: 'The 1990s' vs. 'Buffalo'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s' vs. 'Rutgers'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s' vs. 'American'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s affirmed Stony Brook's' vs. 'the U.S. News & World Report'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s affirmed' vs. 'Shirley Strum Kenny'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s affirmed Stony Brook's success at building' vs. 'the University and Battelle Memorial Institute'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s affirmed Stony' vs. 'the Department of Energy'\n",
            "WARNING:tensorflow:Could not find answer: 'The 1990s affirmed Stony Brook's success' vs. 'the Brookhaven National Laboratories'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of the' vs. 'Kenneth P. LaValle Stadium'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of' vs. 'Charles B. Wang Center'\n",
            "WARNING:tensorflow:Could not find answer: '2002' vs. 'Asian'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw' vs. 'American'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'Charles B. Wang'\n",
            "WARNING:tensorflow:Could not find answer: '2002' vs. 'SUNY'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'Jim Simons'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of the' vs. 'the Stony Brook Foundation'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of the $22 million Kenneth' vs. 'the Simons Center for Geometry and Physics'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'the University'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw' vs. 'Stanley'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'Project 50 Forward'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of the $22 million' vs. 'the University in the next fifty years'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'future.2012'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'University Centers'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'Computer Science'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'Stony Brook Arena'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'the Stony Brook Union'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of the $22 million' vs. 'Medical and Research Translational'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'Shirley Strum Kenny'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'Samuel Stanley Jr'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'Stony Brook's'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'Paul Lauterbur'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of the $22 million' vs. 'a Nobel Prize in Physiology or Medicine'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'NMR Imaging'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'Flowerfield'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of the $22' vs. 'a Research and Development Park'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'National University'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of' vs. 'U.S. News & World Report'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of' vs. 'the 80th Best University'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'Undergraduate'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'Joe Nathan'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'Stuart Goldstein'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the' vs. 'Glenn Dubin'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of' vs. 'Campus Recreation Center'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'Flad Architects'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of the $22' vs. 'Leslie E. Robertson Associates'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening' vs. 'the Wang Center'\n",
            "WARNING:tensorflow:Could not find answer: '2002 saw the opening of the' vs. 'Csar Chvez Hall & Harriet'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Long Island'\n",
            "WARNING:tensorflow:Could not find answer: 'The main' vs. 'Manhattan'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'West Campus'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'East Campus'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'County Road'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Nicolls Road'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in' vs. 'New York State Route'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is' vs. 'North Country Road'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic' vs. 'Ashley Schiff Forest Preserve'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'the South Campus'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'West Campus'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is' vs. 'Stony Brook Station'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic north shore' vs. 'the Simons Center for Geometry and Physics'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic' vs. 'the Administration Building'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic' vs. 'the Student Activity Center'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic' vs. 'Frank Melville Jr. Memorial Library'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Staller Center'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic' vs. 'Humanities, Psychology A & B'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Harriman Hall'\n",
            "WARNING:tensorflow:Could not find answer: 'The main' vs. 'Frey Hall'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Old Chemistry'\n",
            "WARNING:tensorflow:Could not find answer: 'The main' vs. 'Earth'\n",
            "WARNING:tensorflow:Could not find answer: 'The main' vs. 'Physics'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in' vs. 'the Engineering Quad'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic' vs. 'the Engineering, Light Engineering'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is' vs. 'Heavy Engineering'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Computing Center'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic north shore hamlet' vs. 'Javits Lecture Center, Social Behavioral Sciences'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Computer Science'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Student Union'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic north shore' vs. 'the Simons Center for Geometry and Physics'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the historic north' vs. 'Walter J. Hawrys Campus Recreation Center'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is' vs. 'Hilton Garden Inn'\n",
            "WARNING:tensorflow:Could not find answer: 'The main' vs. 'Frey Hall'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Computer Science'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Long Island's'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus' vs. 'Suffolk County'\n",
            "WARNING:tensorflow:Could not find answer: 'The main campus is in the' vs. 'Stony Brook Film Festival'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus' vs. 'the University'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus' vs. 'Flowerfield'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus is about half a mile south' vs. 'the St. James Gyrodyne Company of America'\n",
            "WARNING:tensorflow:Could not find answer: 'The South' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus' vs. 'West Campus'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus is about half' vs. 'Ashley Schiff Forest Preserve'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus is about half a mile south of the' vs. 'the Advanced Energy Research and Technology Center'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus' vs. 'Flad Architects'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus is about' vs. 'the Center of Excellence'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus is about half a mile' vs. 'Wireless and Information Technology'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus is about half' vs. 'the School of Dental Medicine'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus is about half a mile south of' vs. 'the School of Marine and Atmospheric Sciences'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus is about half a mile south of the academic' vs. 'the Cody Center for Autism and Developmental Disabilities'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus' vs. 'University Police'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus' vs. 'Stony Brook Road'\n",
            "WARNING:tensorflow:Could not find answer: 'The South Campus is about half' vs. 'Research and Development Park'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus' vs. 'Suffolk County's'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus is separated' vs. 'Level 1 Trauma Center'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus' vs. 'Suffolk County'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus' vs. 'Nassau County'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus is separated' vs. 'Nicolls Road (County Road'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus is separated from' vs. 'Stony Brook University Hospital'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus is separated' vs. 'the Health Science Center'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus' vs. 'Suffolk County'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus is separated' vs. 'Health Sciences Center'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus is' vs. 'Basic Science Tower'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus is separated' vs. 'the School of Medicine'\n",
            "WARNING:tensorflow:Could not find answer: 'The East Campus' vs. 'Allied Health'\n",
            "WARNING:tensorflow:Could not find answer: 'Also in the' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'Also in the east side of campus are the Chapin' vs. 'Medical and Research Translational Building'\n",
            "WARNING:tensorflow:Could not find answer: 'Also in the east' vs. 'the East Campus'\n",
            "WARNING:tensorflow:Could not find answer: 'Also in the' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'Also in' vs. 'Hospital'\n",
            "WARNING:tensorflow:Could not find answer: 'Also in the east side of' vs. 'Stony Brook Cancer Center'\n",
            "WARNING:tensorflow:Could not find answer: 'Also in the east side of' vs. 'Ambulatory Surgery Center'\n",
            "WARNING:tensorflow:Could not find answer: 'Also in the east' vs. 'the East Campus'\n",
            "WARNING:tensorflow:Could not find answer: 'Also in the' vs. 'Long Island'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the' vs. 'New York City'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the University' vs. 'Southampton College'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the' vs. 'Long Island'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the University' vs. 'Long Island University'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the University' vs. 'Park Avenue South'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the University' vs. 'Park Avenue South'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the University' vs. '387 Park Avenue South'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the University' vs. '101 East 27th Street'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the University' vs. 'Martin Schoonen'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the' vs. 'Southampton'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the' vs. 'Mary Pearl'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002,' vs. 'Manhattan'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the University' vs. 'Stony Brook Manhattan'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2002, the University' vs. 'Long Island University'\n",
            "WARNING:tensorflow:Could not find answer: 'Southampton' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'Southampton campus,' vs. 'the Marine Sciences'\n",
            "WARNING:tensorflow:Could not find answer: 'Southampton campus,' vs. 'Graduate Writing'\n",
            "WARNING:tensorflow:Could not find answer: 'Southampton campus, with its prominent' vs. 'the Faculty Student Association'\n",
            "WARNING:tensorflow:Could not find answer: 'Southampton' vs. 'LIU'\n",
            "WARNING:tensorflow:Could not find answer: 'Southampton campus, with' vs. 'National Public Radio'\n",
            "WARNING:tensorflow:Could not find answer: 'In September 2011 Stony' vs. 'Stony Brook Southampton'\n",
            "WARNING:tensorflow:Could not find answer: 'In' vs. 'Sea'\n",
            "WARNING:tensorflow:Could not find answer: 'In September' vs. 'Ocean'\n",
            "WARNING:tensorflow:Could not find answer: 'In September' vs. 'Ocean'\n",
            "WARNING:tensorflow:Could not find answer: 'In September 2011 Stony' vs. 'Master's of Fine Arts'\n",
            "WARNING:tensorflow:Could not find answer: 'In September' vs. 'Hamptons'\n",
            "WARNING:tensorflow:Could not find answer: 'In September' vs. 'Series'\n",
            "WARNING:tensorflow:Could not find answer: 'As of 2015, the Stony Brook' vs. 'Stony Brook Southampton'\n",
            "WARNING:tensorflow:Could not find answer: 'As of 2015, the Stony Brook Southampton campus has shown' vs. 'the Board of Trustees of the State University of New York'\n",
            "WARNING:tensorflow:Could not find answer: 'As of 2015,' vs. 'Southampton'\n",
            "WARNING:tensorflow:Could not find answer: 'As of 2015, the Stony' vs. 'Stony Brook University'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY board' vs. '200.Stony Brook University'\n",
            "WARNING:tensorflow:Could not find answer: 'In May' vs. 'SUNY'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY' vs. 'Samuel Stanley Jr.'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'South Korean'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY' vs. 'Samuel Stanley Jr.'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY board' vs. 'the Ministry of Education'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY' vs. 'Science and Technology'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'South Korea'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'SUNY Korea'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY board of trustees' vs. 'Songdo International Business District'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY board of' vs. 'North Carolina State University'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'George Mason'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the' vs. 'Carnegie Mellon'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'Johns Hopkins'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the' vs. 'Boston University'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'South Korea'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the' vs. 'Paul W. Zuccaire'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY board' vs. 'the Paul W. Zuccaire Gallery'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY board' vs. 'the University Art Gallery'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY' vs. 'the Staller Center'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the SUNY' vs. 'the Latin American'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'Caribbean'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the' vs. 'Studies Center'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'Art Gallery'\n",
            "WARNING:tensorflow:Could not find answer: 'In May' vs. 'Latino'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009, the' vs. 'Latin American'\n",
            "WARNING:tensorflow:Could not find answer: 'In May 2009,' vs. 'Humanities'\n",
            "WARNING:tensorflow:Could not find answer: 'In May' vs. 'Physics'\n",
            "WARNING:tensorflow:Could not find answer: 'The Stony Brook University consists' vs. 'the College of Arts and Science'\n",
            "WARNING:tensorflow:Could not find answer: 'The University is governed by the' vs. 'the State University of New York'\n",
            "WARNING:tensorflow:Could not find answer: 'The' vs. 'SUNY'\n",
            "WARNING:tensorflow:Could not find answer: 'The University is governed by the' vs. 'the New York State Education Law'\n",
            "WARNING:tensorflow:Could not find answer: 'The University' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'The University' vs. 'the University'\n",
            "WARNING:tensorflow:Could not find answer: 'The University is' vs. 'John Francis Lee'\n",
            "WARNING:tensorflow:Could not find answer: 'The University is' vs. 'Samuel Stanley Jr'\n",
            "WARNING:tensorflow:Could not find answer: 'The University' vs. 'Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'The University is governed' vs. 'the Stony Brook Foundation'\n",
            "WARNING:tensorflow:Could not find answer: 'The University is governed by' vs. 'State University of New York'\n",
            "WARNING:tensorflow:Could not find answer: 'The University is governed' vs. 'the University at Buffalo'\n",
            "WARNING:tensorflow:Could not find answer: 'The University is governed by the State' vs. 'Association of American Universities'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed' vs. 'USG'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed in the' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed in the Student Activity Center,' vs. 'the Student Polity Association (Polity'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed' vs. 'USG'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed in' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed in the Student' vs. 'Student Activity Fee'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed in the Student Activity Center,' vs. 'the Undergraduate Student Government'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed in' vs. 'Homecoming'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed in the Student' vs. 'Roth Pond Regatta'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed in' vs. 'Brookfest'\n",
            "WARNING:tensorflow:Could not find answer: 'Housed in the Student' vs. 'Stony Brook Concerts'\n",
            "WARNING:tensorflow:Could not find answer: 'Like' vs. 'GSO'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook was one of ten' vs. 'National Science Foundation'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook was one of ten national universities' vs. 'the Association of American Universities'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'AAU'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'U.S.'\n",
            "WARNING:tensorflow:Could not find answer: 'In Fall' vs. 'U.S.'\n",
            "WARNING:tensorflow:Could not find answer: 'In Fall 2013, the' vs. 'the United States'\n",
            "WARNING:tensorflow:Could not find answer: 'In Fall' vs. 'Nassau'\n",
            "WARNING:tensorflow:Could not find answer: 'In Fall 2013,' vs. 'Suffolk county'\n",
            "WARNING:tensorflow:Could not find answer: 'In Fall 2013,' vs. 'New York City'\n",
            "WARNING:tensorflow:Could not find answer: 'In Fall 2013,' vs. 'New York City'\n",
            "WARNING:tensorflow:Could not find answer: 'In Fall 2013, the' vs. 'the United States'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2018, U.S. News & World' vs. 'U.S. News & World Report'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2018, U.S. News & World' vs. 'Stony Brook University'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2018, U.S. News & World Report' vs. 'Kiplinger's Personal Finance'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2018, U.S. News' vs. 'Stony Brook 33rd'\n",
            "WARNING:tensorflow:Could not find answer: 'The School of Engineering' vs. 'the School of Social Work'\n",
            "WARNING:tensorflow:Could not find answer: 'The School of Engineering' vs. 'the School of Medicine'\n",
            "WARNING:tensorflow:Could not find answer: 'The School' vs. 'Research'\n",
            "WARNING:tensorflow:Could not find answer: 'The School of' vs. 'Primary Care'\n",
            "WARNING:tensorflow:Could not find answer: 'The School' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Mathematics'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Physician'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear' vs. 'Physics'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Midwifery'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Mathematics'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics (categorized' vs. 'Political Science'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Earth Science'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics (categorized' vs. 'Materials Science'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Engineering'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Computer Science'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics (categorized' vs. 'Occupational Therapy'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics (categorized' vs. 'Biological Sciences'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Chemistry'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear' vs. 'English'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Economics'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Physical Therapy'\n",
            "WARNING:tensorflow:Could not find answer: 'Nuclear Physics' vs. 'Fine Arts'\n",
            "WARNING:tensorflow:Could not find answer: 'Another source, College' vs. 'College Factual's'\n",
            "WARNING:tensorflow:Could not find answer: 'Another source, College' vs. 'Stony Brook University's'\n",
            "WARNING:tensorflow:Could not find answer: 'Another source, College' vs. 'Applied Mathematics'\n",
            "WARNING:tensorflow:Could not find answer: 'Another source, College' vs. 'the United States'\n",
            "WARNING:tensorflow:Could not find answer: 'The School' vs. 'SOMAS'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University' vs. 'James Simons'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages Brookhaven' vs. 'the Simons Center for Geometry and Physics'\n",
            "WARNING:tensorflow:Could not find answer: 'Also,' vs. 'Louis'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages' vs. 'Beatrice Laufer Center'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University' vs. 'Henry Laufer'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages' vs. 'the Department of Defense'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages Brookhaven' vs. 'the Department of Homeland Security'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University' vs. 'the Physical Sciences'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages' vs. 'Mathematics and Engineering'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages' vs. 'Stony Brook University'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages Brookhaven' vs. 'the Institute for Mathematical Sciences'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages Brookhaven National' vs. 'the Institute for Advanced Computational Science'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages Brookhaven National' vs. 'the C. N. Yang Institute for Theoretical Physics'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages' vs. 'the Center for Biotechnology'\n",
            "WARNING:tensorflow:Could not find answer: 'Also, the University co-manages Brookhaven National' vs. 'the Institute of Chemical Biology and Drug Discovery'\n",
            "WARNING:tensorflow:Could not find answer: 'The New York Center for' vs. 'Stony Brook University'\n",
            "WARNING:tensorflow:Could not find answer: 'The New York Center for Computational' vs. 'Brookhaven National Laboratory'\n",
            "WARNING:tensorflow:Could not find answer: 'Its centerpiece' vs. 'Blue Gene'\n",
            "WARNING:tensorflow:Could not find answer: 'Its centerpiece' vs. 'Blue Gene'\n",
            "WARNING:tensorflow:Could not find answer: 'based on the IBM system-on-chip' vs. 'New York Blue Gene/L'\n",
            "WARNING:tensorflow:Could not find answer: 'based on the' vs. 'Blue Gene/P'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2016, Stony' vs. 'Long Island'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2016, Stony Brook University placed second' vs. 'the New York State Business Plan Competition'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook has a wide' vs. 'Stony Brook University'\n",
            "WARNING:tensorflow:Could not find answer: 'The oldest' vs. 'Statesman'\n",
            "WARNING:tensorflow:Could not find answer: 'The oldest' vs. 'Oyster Bay'\n",
            "WARNING:tensorflow:Could not find answer: 'The oldest campus newspaper' vs. 'the Stony Brook Press'\n",
            "WARNING:tensorflow:Could not find answer: 'The oldest campus newspaper' vs. 'Stony Brook Independent'\n",
            "WARNING:tensorflow:Could not find answer: 'The oldest' vs. 'Blackworld'\n",
            "WARNING:tensorflow:Could not find answer: 'The oldest campus' vs. 'the Asian American'\n",
            "WARNING:tensorflow:Could not find answer: 'The' vs. 'WUSB'\n",
            "WARNING:tensorflow:Could not find answer: 'The oldest' vs. 'Long Island'\n",
            "WARNING:tensorflow:Could not find answer: 'The oldest' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth Pond' vs. 'Bruno Mars'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth Pond in' vs. 'Janelle Mone'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth Pond in' vs. 'Wiz Khalifa'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth Pond' vs. 'Miguel'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth Pond' vs. 'Ludacris'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth' vs. 'Diplo'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth Pond' vs. 'Roth Quad'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth Pond in Roth Quad,' vs. 'Roth Pond RegattaOne'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth Pond in Roth' vs. 'Roth Pond Regatta'\n",
            "WARNING:tensorflow:Could not find answer: 'Roth Pond in' vs. 'the Roth Pond'\n",
            "WARNING:tensorflow:Could not find answer: '' vs. 'SAC'\n",
            "WARNING:tensorflow:Could not find answer: '' vs. 'Stony Brook Concert Series'\n",
            "WARNING:tensorflow:Could not find answer: '' vs. 'Frank Zappa'\n",
            "WARNING:tensorflow:Could not find answer: '' vs. 'Jimi Hendrix'\n",
            "WARNING:tensorflow:Could not find answer: '' vs. 'Janice Joplin'\n",
            "WARNING:tensorflow:Could not find answer: '' vs. 'Grateful Dead'\n",
            "WARNING:tensorflow:Could not find answer: '' vs. 'the Allman Brothers'\n",
            "WARNING:tensorflow:Could not find answer: '' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'Weekly, throughout' vs. 'Campus Life Time'\n",
            "WARNING:tensorflow:Could not find answer: 'Weekly, throughout' vs. 'Stony Brook'\n",
            "WARNING:tensorflow:Could not find answer: 'Weekly, throughout' vs. 'Strawberry Fest'\n",
            "WARNING:tensorflow:Could not find answer: 'Weekly, throughout' vs. 'Campus Life Time'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase series takes place on' vs. 'the Undergraduate Student Government'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase' vs. 'Vs Zombies'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase series takes' vs. 'the Provost Lecture Series'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase' vs. 'Daniel Ellsberg'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase' vs. 'Ralph Nader'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase' vs. 'Shirley Strum'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase series' vs. 'the Academic Mall'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase series takes place' vs. 'the Stony Brook Film Festival'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase series takes' vs. 'the Emerson String Quartet'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase series takes' vs. 'the Department of Music'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase series' vs. 'the Staller Center'\n",
            "WARNING:tensorflow:Could not find answer: 'RockYoFaceCase' vs. 'Staller'\n",
            "WARNING:tensorflow:Could not find answer: 'The Spirit of Stony Brook University' vs. 'Stony Brook University Marching Band'\n",
            "WARNING:tensorflow:Could not find answer: 'The Spirit of Stony Brook University Marching' vs. 'the America East Men's Basketball Tournament'\n",
            "WARNING:tensorflow:Could not find answer: 'The Spirit of Stony Brook' vs. 'Stony Brook Marching Band'\n",
            "WARNING:tensorflow:Could not find answer: 'The Spirit of Stony' vs. 'Extreme Makeover'\n",
            "WARNING:tensorflow:Could not find answer: 'The Spirit of' vs. 'Home Edition'\n",
            "WARNING:tensorflow:Could not find answer: 'The Spirit of Stony' vs. 'the New York Lottery'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook University's intercollegiate' vs. 'the America East Conference'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook University's intercollegiate athletics teams, known as the' vs. 'the Football Championship Subdivision's Colonial Athletic Association'\n",
            "WARNING:tensorflow:Could not find answer: 'On March 12, 2016, the' vs. 'America East Conference'\n",
            "WARNING:tensorflow:Could not find answer: 'On March' vs. 'Vermont'\n",
            "WARNING:tensorflow:Could not find answer: 'On March' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent' vs. 'University'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent years the Seawolves' vs. 'a Big South Co-Championship'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent years the Seawolves' vs. 'the Women's Cross Country'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent years' vs. 'Men's Soccer'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent' vs. 'Baseball'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent years' vs. 'Men's Lacrosse'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent years' vs. 'LaValle Stadium'\n",
            "WARNING:tensorflow:Could not find answer: 'In' vs. 'Men'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent years the Seawolves have' vs. 'the National Invitation Tournament'\n",
            "WARNING:tensorflow:Could not find answer: 'In recent' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'With increased expectations,' vs. 'Big South Co-Championship'\n",
            "WARNING:tensorflow:Could not find answer: 'With' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'With' vs. 'Men'\n",
            "WARNING:tensorflow:Could not find answer: 'With' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'With increased' vs. 'Baseball'\n",
            "WARNING:tensorflow:Could not find answer: 'With' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'With increased expectations,' vs. 'the Women's Cross Country'\n",
            "WARNING:tensorflow:Could not find answer: 'With' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'With increased' vs. 'Championship'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook' vs. 'Seawolves'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook' vs. 'Joe Spallina'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'Women'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook' vs. 'Adelphi'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans' vs. 'the America East'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'Men'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans' vs. 'the America East'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'NIT'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'MLB'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans rush the field after a memorable' vs. 'National Collegiate Baseball Writers Association'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook' vs. 'Matt Senk'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook' vs. 'Seawolves'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'Soccer'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans rush the' vs. 'America East Championship'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook' vs. 'America East'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'Women'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans rush the' vs. 'Conference Championship'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans' vs. 'LaValle Stadium'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans' vs. 'Track & Field'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans' vs. 'Lucy Van Dalen'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans' vs. 'Stony Brook's'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans' vs. 'National Champion'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans rush' vs. 'the NCAA Indoor Track'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook' vs. 'Jim Nagle'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans' vs. 'the America East'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'NCAA'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook' vs. 'Conference'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony' vs. 'Men's'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans rush' vs. 'Women's Cross Country'\n",
            "WARNING:tensorflow:Could not find answer: 'Stony Brook fans rush' vs. 'Big South Championship'\n",
            "WARNING:tensorflow:Could not find answer: 'In 2013, Stony Brook' vs. 'Wolf Ride Bike Share'\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff8d22d48c8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/Downloads/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff8d1dbf400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000000\n",
            "INFO:tensorflow:example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] in 2013 , what launched its own bike share system to provide a sustainable transportation alternative for students ( wolf ride bike share ) . [SEP] in 2013 , stony brook university launched its own bike share system to provide a sustainable transportation alternative for students ( wolf ride bike share ) . in 2016 , the university provides 8 stations and 63 bikes . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 27:0 28:1 29:1 30:2 31:3 32:4 33:5 34:6 35:7 36:8 37:9 38:10 39:11 40:12 41:13 42:14 43:15 44:16 45:17 46:18 47:19 48:19 49:20 50:21 51:22 52:22 53:22 54:23 55:24 56:24 57:25 58:26 59:27 60:28 61:29 62:30 63:31 64:32 65:32\n",
            "INFO:tensorflow:token_is_max_context: 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True\n",
            "INFO:tensorflow:input_ids: 101 1999 2286 1010 2054 3390 2049 2219 7997 3745 2291 2000 3073 1037 9084 5193 4522 2005 2493 1006 4702 4536 7997 3745 1007 1012 102 1999 2286 1010 16104 9566 2118 3390 2049 2219 7997 3745 2291 2000 3073 1037 9084 5193 4522 2005 2493 1006 4702 4536 7997 3745 1007 1012 1999 2355 1010 1996 2118 3640 1022 3703 1998 6191 18105 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 30\n",
            "INFO:tensorflow:end_position: 32\n",
            "INFO:tensorflow:answer: stony brook university\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000001\n",
            "INFO:tensorflow:example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] the what of stony brook university marching band was created in 2006 and plays at athletic games and other events . [SEP] the spirit of stony brook university marching band was created in 2006 and plays at athletic games and other events . the first public performance was at the september 2006 con ##vocation . the band grew to 70 members the second year and added additional staff . the band first traveled to the america east men ' s basketball tournament in march 2007 and has done so regularly ever since . by july 2008 , the band had reached 100 members . the stony brook marching band first participated in the nyc columbus day parade in 2011 , as well as appeared in an episode of extreme make ##over : home edition and a commercial for the new york lottery , further ##ing their exposure state and nationwide . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 23:0 24:1 25:2 26:3 27:4 28:5 29:6 30:7 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:19 44:20 45:21 46:22 47:23 48:24 49:25 50:26 51:27 52:28 53:29 54:29 55:29 56:30 57:31 58:32 59:33 60:34 61:35 62:36 63:37 64:38 65:39 66:40 67:41 68:42 69:42 70:42 71:43 72:44 73:45 74:46 75:47 76:48 77:49 78:50 79:50 80:50 81:51 82:52 83:53 84:54 85:55 86:56 87:57 88:58 89:59 90:60 91:61 92:62 93:62 94:63 95:64 96:65 97:65 98:66 99:67 100:68 101:69 102:70 103:71 104:71 105:71 106:72 107:73 108:74 109:75 110:76 111:77 112:78 113:79 114:80 115:81 116:82 117:83 118:84 119:85 120:85 121:86 122:87 123:88 124:89 125:90 126:91 127:92 128:93 129:94 130:95 131:95 132:95 133:96 134:97 135:98 136:99 137:100 138:101 139:102 140:103 141:104 142:105 143:105 144:106 145:106 146:107 147:108 148:109 149:110 150:111 151:111\n",
            "INFO:tensorflow:token_is_max_context: 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True\n",
            "INFO:tensorflow:input_ids: 101 1996 2054 1997 16104 9566 2118 10998 2316 2001 2580 1999 2294 1998 3248 2012 5188 2399 1998 2060 2824 1012 102 1996 4382 1997 16104 9566 2118 10998 2316 2001 2580 1999 2294 1998 3248 2012 5188 2399 1998 2060 2824 1012 1996 2034 2270 2836 2001 2012 1996 2244 2294 9530 19152 1012 1996 2316 3473 2000 3963 2372 1996 2117 2095 1998 2794 3176 3095 1012 1996 2316 2034 6158 2000 1996 2637 2264 2273 1005 1055 3455 2977 1999 2233 2289 1998 2038 2589 2061 5570 2412 2144 1012 2011 2251 2263 1010 1996 2316 2018 2584 2531 2372 1012 1996 16104 9566 10998 2316 2034 4194 1999 1996 16392 8912 2154 7700 1999 2249 1010 2004 2092 2004 2596 1999 2019 2792 1997 6034 2191 7840 1024 2188 3179 1998 1037 3293 2005 1996 2047 2259 15213 1010 2582 2075 2037 7524 2110 1998 9053 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 24\n",
            "INFO:tensorflow:end_position: 24\n",
            "INFO:tensorflow:answer: spirit\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000002\n",
            "INFO:tensorflow:example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] new york institute of technology placed first with four teams qualifying for the state competition ' s final round , while what had three teams qualifying for the state competition ' s final round . [SEP] in 2016 , stony brook university placed second at the long island regional round of the new york state business plan competition . new york institute of technology placed first with four teams qualifying for the state competition ' s final round , while stony brook university had three teams qualifying for the state competition ' s final round . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 37:0 38:1 39:1 40:2 41:3 42:4 43:5 44:6 45:7 46:8 47:9 48:10 49:11 50:12 51:13 52:14 53:15 54:16 55:17 56:18 57:19 58:20 59:20 60:21 61:22 62:23 63:24 64:25 65:26 66:27 67:28 68:29 69:30 70:31 71:32 72:33 73:34 74:35 75:35 76:35 77:36 78:37 79:37 80:38 81:39 82:40 83:41 84:42 85:43 86:44 87:45 88:46 89:47 90:48 91:49 92:49 93:49 94:50 95:51 96:51\n",
            "INFO:tensorflow:token_is_max_context: 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True\n",
            "INFO:tensorflow:input_ids: 101 2047 2259 2820 1997 2974 2872 2034 2007 2176 2780 6042 2005 1996 2110 2971 1005 1055 2345 2461 1010 2096 2054 2018 2093 2780 6042 2005 1996 2110 2971 1005 1055 2345 2461 1012 102 1999 2355 1010 16104 9566 2118 2872 2117 2012 1996 2146 2479 3164 2461 1997 1996 2047 2259 2110 2449 2933 2971 1012 2047 2259 2820 1997 2974 2872 2034 2007 2176 2780 6042 2005 1996 2110 2971 1005 1055 2345 2461 1010 2096 16104 9566 2118 2018 2093 2780 6042 2005 1996 2110 2971 1005 1055 2345 2461 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 40\n",
            "INFO:tensorflow:end_position: 42\n",
            "INFO:tensorflow:answer: stony brook university\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000003\n",
            "INFO:tensorflow:example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] the 18 , 000 - square - foot ( 1 , 700 what m2 ) site allows stony brook to offer professional and graduate courses targeted towards students in new york city ; undergraduate courses are held primarily during the summer and winter sessions . [SEP] in 2002 , the university established a presence in manhattan with the opening of stony brook manhattan . the original site was at 401 park avenue south ; a newer operation opened in late 2008 in the adjacent building on the third floor of 38 ##7 park avenue south . the university consolidated operations in 2011 to just the 3rd floor of 38 ##7 park avenue south , with a classroom entrance around the corner at 101 east 27th street . the 18 , 000 - square - foot ( 1 , 700 m2 ) site allows stony brook to offer professional and graduate courses targeted towards students in new york city ; undergraduate courses are held primarily during the summer and winter sessions . conferences and special events take place throughout the year . in february 2017 however , the lease for this campus was terminated , and there are no classes offered at this location . on march 24 , 2006 , the university completed the purchase of the 81 - acre ( 330 , 000 m2 ) southampton college ( on the east end of long island ) property from long island university with the intent to develop it as a full college campus focusing on academic programs related to the environment and sustainability . stony brook expanded its original program , started in the fall of 2005 , when it offered an undergraduate marine sciences program , with teaching and research facilities at the campus leased from long island university . an enrollment of about 2 , 000 students is expected within the next five years . professor martin sc ##ho ##one ##n was appointed interim dean of southampton campus on august 3 , 2006 , and conservation ##ist mary pearl was appointed dean and vice president in march 2009 . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 47:0 48:1 49:1 50:2 51:3 52:4 53:5 54:6 55:7 56:8 57:9 58:10 59:11 60:12 61:13 62:14 63:15 64:15 65:16 66:17 67:18 68:19 69:20 70:21 71:22 72:23 73:24 74:24 75:25 76:26 77:27 78:28 79:29 80:30 81:31 82:32 83:33 84:34 85:35 86:36 87:37 88:38 89:39 90:40 91:41 92:41 93:42 94:43 95:44 96:44 97:45 98:46 99:47 100:48 101:49 102:50 103:51 104:52 105:53 106:54 107:55 108:56 109:57 110:57 111:58 112:59 113:60 114:60 115:61 116:62 117:63 118:64 119:65 120:66 121:67 122:68 123:69 124:70 125:71 126:72 127:72 128:73 129:74 130:74 131:74 132:74 133:74 134:74 135:74 136:75 137:75 138:75 139:75 140:75 141:75 142:76 143:77 144:78 145:79 146:80 147:81 148:82 149:83 150:84 151:85 152:86 153:87 154:88 155:89 156:90 157:91 158:92 159:92 160:93 161:94 162:95 163:96 164:97 165:98 166:99 167:100 168:101 169:102 170:103 171:103 172:104 173:105 174:106 175:107 176:108 177:109 178:110 179:111 180:112 181:112 182:113 183:114 184:115 185:116 186:116 187:117 188:118 189:119 190:120 191:121 192:122 193:123 194:123 195:124 196:125 197:126 198:127 199:128 200:129 201:130 202:131 203:132 204:132 205:132 206:133 207:134 208:134 209:135 210:135 211:136 212:137 213:138 214:139 215:140 216:141 217:142 218:143 219:143 220:143 221:144 222:144 223:144 224:144 225:144 226:144 227:145 228:146 229:147 230:147 231:148 232:149 233:150 234:151 235:152 236:153 237:153 238:154 239:155 240:156 241:157 242:158 243:159 244:160 245:161 246:162 247:163 248:164 249:165 250:166 251:167 252:168 253:169 254:170 255:171 256:172 257:173 258:174 259:175 260:176 261:177 262:178 263:179 264:179 265:180 266:181 267:182 268:183 269:184 270:185 271:185 272:186 273:187 274:188 275:189 276:190 277:191 278:191 279:192 280:193 281:194 282:195 283:196 284:197 285:198 286:199 287:199 288:200 289:201 290:202 291:203 292:204 293:205 294:206 295:207 296:208 297:209 298:210 299:211 300:212 301:212 302:213 303:214 304:215 305:216 306:217 307:217 308:217 309:218 310:219 311:220 312:221 313:222 314:223 315:224 316:225 317:225 318:226 319:227 320:228 321:228 322:228 323:228 324:229 325:230 326:231 327:232 328:233 329:234 330:235 331:236 332:237 333:238 334:238 335:239 336:239 337:240 338:241 339:241 340:242 341:243 342:244 343:245 344:246 345:247 346:248 347:249 348:250 349:251 350:252 351:252\n",
            "INFO:tensorflow:token_is_max_context: 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True\n",
            "INFO:tensorflow:input_ids: 101 1996 2324 1010 2199 1011 2675 1011 3329 1006 1015 1010 6352 2054 25525 1007 2609 4473 16104 9566 2000 3749 2658 1998 4619 5352 9416 2875 2493 1999 2047 2259 2103 1025 8324 5352 2024 2218 3952 2076 1996 2621 1998 3467 6521 1012 102 1999 2526 1010 1996 2118 2511 1037 3739 1999 7128 2007 1996 3098 1997 16104 9566 7128 1012 1996 2434 2609 2001 2012 22649 2380 3927 2148 1025 1037 10947 3169 2441 1999 2397 2263 1999 1996 5516 2311 2006 1996 2353 2723 1997 4229 2581 2380 3927 2148 1012 1996 2118 10495 3136 1999 2249 2000 2074 1996 3822 2723 1997 4229 2581 2380 3927 2148 1010 2007 1037 9823 4211 2105 1996 3420 2012 7886 2264 15045 2395 1012 1996 2324 1010 2199 1011 2675 1011 3329 1006 1015 1010 6352 25525 1007 2609 4473 16104 9566 2000 3749 2658 1998 4619 5352 9416 2875 2493 1999 2047 2259 2103 1025 8324 5352 2024 2218 3952 2076 1996 2621 1998 3467 6521 1012 9281 1998 2569 2824 2202 2173 2802 1996 2095 1012 1999 2337 2418 2174 1010 1996 10084 2005 2023 3721 2001 12527 1010 1998 2045 2024 2053 4280 3253 2012 2023 3295 1012 2006 2233 2484 1010 2294 1010 1996 2118 2949 1996 5309 1997 1996 6282 1011 7456 1006 14210 1010 2199 25525 1007 11833 2267 1006 2006 1996 2264 2203 1997 2146 2479 1007 3200 2013 2146 2479 2118 2007 1996 7848 2000 4503 2009 2004 1037 2440 2267 3721 7995 2006 3834 3454 3141 2000 1996 4044 1998 15169 1012 16104 9566 4423 2049 2434 2565 1010 2318 1999 1996 2991 1997 2384 1010 2043 2009 3253 2019 8324 3884 4163 2565 1010 2007 4252 1998 2470 4128 2012 1996 3721 12019 2013 2146 2479 2118 1012 2019 10316 1997 2055 1016 1010 2199 2493 2003 3517 2306 1996 2279 2274 2086 1012 2934 3235 8040 6806 5643 2078 2001 2805 9455 4670 1997 11833 3721 2006 2257 1017 1010 2294 1010 1998 5680 2923 2984 7247 2001 2805 4670 1998 3580 2343 1999 2233 2268 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 47\n",
            "INFO:tensorflow:end_position: 47\n",
            "INFO:tensorflow:answer: in\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000004\n",
            "INFO:tensorflow:example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] the what ' s students study coastal ocean ##ographic processes and atmospheric sciences in a natural and academic setting that offers abundant opportunities for conducting field work , solving real problems in both local and distant environments , and learning to express their opinions in the weekly seminars . [SEP] the school of marine and atmospheric sciences ( so ##mas ) is the sun ##y center for marine and atmospheric research , education , and public service . more than 300 graduate and undergraduate students from 16 different nations work and study at so ##mas . the school ' s students study coastal ocean ##ographic processes and atmospheric sciences in a natural and academic setting that offers abundant opportunities for conducting field work , solving real problems in both local and distant environments , and learning to express their opinions in the weekly seminars . the marine sciences research center , the original institute for marine studies , was incorporated into the new school of marine and atmospheric sciences ( so ##mas ) on june 15 , 2007 . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 51:0 52:1 53:2 54:3 55:4 56:5 57:6 58:7 59:7 60:7 61:7 62:8 63:9 64:10 65:10 66:11 67:12 68:13 69:14 70:15 71:16 72:16 73:17 74:17 75:18 76:19 77:20 78:20 79:21 80:22 81:23 82:24 83:25 84:26 85:27 86:28 87:29 88:30 89:31 90:32 91:33 92:34 93:35 94:36 95:36 96:36 97:37 98:38 99:38 100:38 101:39 102:40 103:41 104:42 105:42 106:43 107:44 108:45 109:46 110:47 111:48 112:49 113:50 114:51 115:52 116:53 117:54 118:55 119:56 120:57 121:58 122:59 123:60 124:60 125:61 126:62 127:63 128:64 129:65 130:66 131:67 132:68 133:69 134:69 135:70 136:71 137:72 138:73 139:74 140:75 141:76 142:77 143:78 144:79 145:79 146:80 147:81 148:82 149:83 150:84 151:84 152:85 153:86 154:87 155:88 156:89 157:90 158:90 159:91 160:92 161:93 162:94 163:95 164:96 165:97 166:98 167:99 168:100 169:101 170:102 171:102 172:102 173:102 174:103 175:104 176:105 177:105 178:106 179:106\n",
            "INFO:tensorflow:token_is_max_context: 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True\n",
            "INFO:tensorflow:input_ids: 101 1996 2054 1005 1055 2493 2817 5780 4153 13705 6194 1998 12483 4163 1999 1037 3019 1998 3834 4292 2008 4107 12990 6695 2005 9283 2492 2147 1010 13729 2613 3471 1999 2119 2334 1998 6802 10058 1010 1998 4083 2000 4671 2037 10740 1999 1996 4882 17239 1012 102 1996 2082 1997 3884 1998 12483 4163 1006 2061 9335 1007 2003 1996 3103 2100 2415 2005 3884 1998 12483 2470 1010 2495 1010 1998 2270 2326 1012 2062 2084 3998 4619 1998 8324 2493 2013 2385 2367 3741 2147 1998 2817 2012 2061 9335 1012 1996 2082 1005 1055 2493 2817 5780 4153 13705 6194 1998 12483 4163 1999 1037 3019 1998 3834 4292 2008 4107 12990 6695 2005 9283 2492 2147 1010 13729 2613 3471 1999 2119 2334 1998 6802 10058 1010 1998 4083 2000 4671 2037 10740 1999 1996 4882 17239 1012 1996 3884 4163 2470 2415 1010 1996 2434 2820 2005 3884 2913 1010 2001 5100 2046 1996 2047 2082 1997 3884 1998 12483 4163 1006 2061 9335 1007 2006 2238 2321 1010 2289 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 52\n",
            "INFO:tensorflow:end_position: 52\n",
            "INFO:tensorflow:answer: school\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000005\n",
            "INFO:tensorflow:example_index: 5\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] in 2016 , what placed second at the long island regional round of the new york state business plan competition . [SEP] in 2016 , stony brook university placed second at the long island regional round of the new york state business plan competition . new york institute of technology placed first with four teams qualifying for the state competition ' s final round , while stony brook university had three teams qualifying for the state competition ' s final round . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 23:0 24:1 25:1 26:2 27:3 28:4 29:5 30:6 31:7 32:8 33:9 34:10 35:11 36:12 37:13 38:14 39:15 40:16 41:17 42:18 43:19 44:20 45:20 46:21 47:22 48:23 49:24 50:25 51:26 52:27 53:28 54:29 55:30 56:31 57:32 58:33 59:34 60:35 61:35 62:35 63:36 64:37 65:37 66:38 67:39 68:40 69:41 70:42 71:43 72:44 73:45 74:46 75:47 76:48 77:49 78:49 79:49 80:50 81:51 82:51\n",
            "INFO:tensorflow:token_is_max_context: 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True\n",
            "INFO:tensorflow:input_ids: 101 1999 2355 1010 2054 2872 2117 2012 1996 2146 2479 3164 2461 1997 1996 2047 2259 2110 2449 2933 2971 1012 102 1999 2355 1010 16104 9566 2118 2872 2117 2012 1996 2146 2479 3164 2461 1997 1996 2047 2259 2110 2449 2933 2971 1012 2047 2259 2820 1997 2974 2872 2034 2007 2176 2780 6042 2005 1996 2110 2971 1005 1055 2345 2461 1010 2096 16104 9566 2118 2018 2093 2780 6042 2005 1996 2110 2971 1005 1055 2345 2461 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 26\n",
            "INFO:tensorflow:end_position: 28\n",
            "INFO:tensorflow:answer: stony brook university\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000006\n",
            "INFO:tensorflow:example_index: 6\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] on march 24 , 2006 , what completed the purchase of the 81 - acre ( 330 , 000 m2 ) southampton college ( on the east end of long island ) property from long island university with the intent to develop it as a full college campus focusing on academic programs related to the environment and sustainability . [SEP] in 2002 , the university established a presence in manhattan with the opening of stony brook manhattan . the original site was at 401 park avenue south ; a newer operation opened in late 2008 in the adjacent building on the third floor of 38 ##7 park avenue south . the university consolidated operations in 2011 to just the 3rd floor of 38 ##7 park avenue south , with a classroom entrance around the corner at 101 east 27th street . the 18 , 000 - square - foot ( 1 , 700 m2 ) site allows stony brook to offer professional and graduate courses targeted towards students in new york city ; undergraduate courses are held primarily during the summer and winter sessions . conferences and special events take place throughout the year . in february 2017 however , the lease for this campus was terminated , and there are no classes offered at this location . on march 24 , 2006 , the university completed the purchase of the 81 - acre ( 330 , 000 m2 ) southampton college ( on the east end of long island ) property from long island university with the intent to develop it as a full college campus focusing on academic programs related to the environment and sustainability . stony brook expanded its original program , started in the fall of 2005 , when it offered an undergraduate marine sciences program , with teaching and research facilities at the campus leased from long island university . an enrollment of about 2 , 000 students is expected within the next five years . professor martin sc ##ho ##one ##n was appointed interim dean of southampton campus on august 3 , 2006 , and conservation ##ist mary pearl was appointed dean and vice president in march 2009 . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 61:0 62:1 63:1 64:2 65:3 66:4 67:5 68:6 69:7 70:8 71:9 72:10 73:11 74:12 75:13 76:14 77:15 78:15 79:16 80:17 81:18 82:19 83:20 84:21 85:22 86:23 87:24 88:24 89:25 90:26 91:27 92:28 93:29 94:30 95:31 96:32 97:33 98:34 99:35 100:36 101:37 102:38 103:39 104:40 105:41 106:41 107:42 108:43 109:44 110:44 111:45 112:46 113:47 114:48 115:49 116:50 117:51 118:52 119:53 120:54 121:55 122:56 123:57 124:57 125:58 126:59 127:60 128:60 129:61 130:62 131:63 132:64 133:65 134:66 135:67 136:68 137:69 138:70 139:71 140:72 141:72 142:73 143:74 144:74 145:74 146:74 147:74 148:74 149:74 150:75 151:75 152:75 153:75 154:75 155:75 156:76 157:77 158:78 159:79 160:80 161:81 162:82 163:83 164:84 165:85 166:86 167:87 168:88 169:89 170:90 171:91 172:92 173:92 174:93 175:94 176:95 177:96 178:97 179:98 180:99 181:100 182:101 183:102 184:103 185:103 186:104 187:105 188:106 189:107 190:108 191:109 192:110 193:111 194:112 195:112 196:113 197:114 198:115 199:116 200:116 201:117 202:118 203:119 204:120 205:121 206:122 207:123 208:123 209:124 210:125 211:126 212:127 213:128 214:129 215:130 216:131 217:132 218:132 219:132 220:133 221:134 222:134 223:135 224:135 225:136 226:137 227:138 228:139 229:140 230:141 231:142 232:143 233:143 234:143 235:144 236:144 237:144 238:144 239:144 240:144 241:145 242:146 243:147 244:147 245:148 246:149 247:150 248:151 249:152 250:153 251:153 252:154 253:155 254:156 255:157 256:158 257:159 258:160 259:161 260:162 261:163 262:164 263:165 264:166 265:167 266:168 267:169 268:170 269:171 270:172 271:173 272:174 273:175 274:176 275:177 276:178 277:179 278:179 279:180 280:181 281:182 282:183 283:184 284:185 285:185 286:186 287:187 288:188 289:189 290:190 291:191 292:191 293:192 294:193 295:194 296:195 297:196 298:197 299:198 300:199 301:199 302:200 303:201 304:202 305:203 306:204 307:205 308:206 309:207 310:208 311:209 312:210 313:211 314:212 315:212 316:213 317:214 318:215 319:216 320:217 321:217 322:217 323:218 324:219 325:220 326:221 327:222 328:223 329:224 330:225 331:225 332:226 333:227 334:228 335:228 336:228 337:228 338:229 339:230 340:231 341:232 342:233 343:234 344:235 345:236 346:237 347:238 348:238 349:239 350:239 351:240 352:241 353:241 354:242 355:243 356:244 357:245 358:246 359:247 360:248 361:249 362:250 363:251 364:252 365:252\n",
            "INFO:tensorflow:token_is_max_context: 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True\n",
            "INFO:tensorflow:input_ids: 101 2006 2233 2484 1010 2294 1010 2054 2949 1996 5309 1997 1996 6282 1011 7456 1006 14210 1010 2199 25525 1007 11833 2267 1006 2006 1996 2264 2203 1997 2146 2479 1007 3200 2013 2146 2479 2118 2007 1996 7848 2000 4503 2009 2004 1037 2440 2267 3721 7995 2006 3834 3454 3141 2000 1996 4044 1998 15169 1012 102 1999 2526 1010 1996 2118 2511 1037 3739 1999 7128 2007 1996 3098 1997 16104 9566 7128 1012 1996 2434 2609 2001 2012 22649 2380 3927 2148 1025 1037 10947 3169 2441 1999 2397 2263 1999 1996 5516 2311 2006 1996 2353 2723 1997 4229 2581 2380 3927 2148 1012 1996 2118 10495 3136 1999 2249 2000 2074 1996 3822 2723 1997 4229 2581 2380 3927 2148 1010 2007 1037 9823 4211 2105 1996 3420 2012 7886 2264 15045 2395 1012 1996 2324 1010 2199 1011 2675 1011 3329 1006 1015 1010 6352 25525 1007 2609 4473 16104 9566 2000 3749 2658 1998 4619 5352 9416 2875 2493 1999 2047 2259 2103 1025 8324 5352 2024 2218 3952 2076 1996 2621 1998 3467 6521 1012 9281 1998 2569 2824 2202 2173 2802 1996 2095 1012 1999 2337 2418 2174 1010 1996 10084 2005 2023 3721 2001 12527 1010 1998 2045 2024 2053 4280 3253 2012 2023 3295 1012 2006 2233 2484 1010 2294 1010 1996 2118 2949 1996 5309 1997 1996 6282 1011 7456 1006 14210 1010 2199 25525 1007 11833 2267 1006 2006 1996 2264 2203 1997 2146 2479 1007 3200 2013 2146 2479 2118 2007 1996 7848 2000 4503 2009 2004 1037 2440 2267 3721 7995 2006 3834 3454 3141 2000 1996 4044 1998 15169 1012 16104 9566 4423 2049 2434 2565 1010 2318 1999 1996 2991 1997 2384 1010 2043 2009 3253 2019 8324 3884 4163 2565 1010 2007 4252 1998 2470 4128 2012 1996 3721 12019 2013 2146 2479 2118 1012 2019 10316 1997 2055 1016 1010 2199 2493 2003 3517 2306 1996 2279 2274 2086 1012 2934 3235 8040 6806 5643 2078 2001 2805 9455 4670 1997 11833 3721 2006 2257 1017 1010 2294 1010 1998 5680 2923 2984 7247 2001 2805 4670 1998 3580 2343 1999 2233 2268 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 64\n",
            "INFO:tensorflow:end_position: 65\n",
            "INFO:tensorflow:answer: the university\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000007\n",
            "INFO:tensorflow:example_index: 7\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] on march 24 , 2006 , the university completed the purchase of the 81 - acre ( 330 , 000 what m2 ) southampton college ( on the east end of long island ) property from long island university with the intent to develop it as a full college campus focusing on academic programs related to the environment and sustainability . [SEP] in 2002 , the university established a presence in manhattan with the opening of stony brook manhattan . the original site was at 401 park avenue south ; a newer operation opened in late 2008 in the adjacent building on the third floor of 38 ##7 park avenue south . the university consolidated operations in 2011 to just the 3rd floor of 38 ##7 park avenue south , with a classroom entrance around the corner at 101 east 27th street . the 18 , 000 - square - foot ( 1 , 700 m2 ) site allows stony brook to offer professional and graduate courses targeted towards students in new york city ; undergraduate courses are held primarily during the summer and winter sessions . conferences and special events take place throughout the year . in february 2017 however , the lease for this campus was terminated , and there are no classes offered at this location . on march 24 , 2006 , the university completed the purchase of the 81 - acre ( 330 , 000 m2 ) southampton college ( on the east end of long island ) property from long island university with the intent to develop it as a full college campus focusing on academic programs related to the environment and sustainability . stony brook expanded its original program , started in the fall of 2005 , when it offered an undergraduate marine sciences program , with teaching and research facilities at the campus leased from long island university . an enrollment of about 2 , 000 students is expected within the next five years . professor martin sc ##ho ##one ##n was appointed interim dean of southampton campus on august 3 , 2006 , and conservation ##ist mary pearl was appointed dean and vice president in march 2009 . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 63:0 64:1 65:1 66:2 67:3 68:4 69:5 70:6 71:7 72:8 73:9 74:10 75:11 76:12 77:13 78:14 79:15 80:15 81:16 82:17 83:18 84:19 85:20 86:21 87:22 88:23 89:24 90:24 91:25 92:26 93:27 94:28 95:29 96:30 97:31 98:32 99:33 100:34 101:35 102:36 103:37 104:38 105:39 106:40 107:41 108:41 109:42 110:43 111:44 112:44 113:45 114:46 115:47 116:48 117:49 118:50 119:51 120:52 121:53 122:54 123:55 124:56 125:57 126:57 127:58 128:59 129:60 130:60 131:61 132:62 133:63 134:64 135:65 136:66 137:67 138:68 139:69 140:70 141:71 142:72 143:72 144:73 145:74 146:74 147:74 148:74 149:74 150:74 151:74 152:75 153:75 154:75 155:75 156:75 157:75 158:76 159:77 160:78 161:79 162:80 163:81 164:82 165:83 166:84 167:85 168:86 169:87 170:88 171:89 172:90 173:91 174:92 175:92 176:93 177:94 178:95 179:96 180:97 181:98 182:99 183:100 184:101 185:102 186:103 187:103 188:104 189:105 190:106 191:107 192:108 193:109 194:110 195:111 196:112 197:112 198:113 199:114 200:115 201:116 202:116 203:117 204:118 205:119 206:120 207:121 208:122 209:123 210:123 211:124 212:125 213:126 214:127 215:128 216:129 217:130 218:131 219:132 220:132 221:132 222:133 223:134 224:134 225:135 226:135 227:136 228:137 229:138 230:139 231:140 232:141 233:142 234:143 235:143 236:143 237:144 238:144 239:144 240:144 241:144 242:144 243:145 244:146 245:147 246:147 247:148 248:149 249:150 250:151 251:152 252:153 253:153 254:154 255:155 256:156 257:157 258:158 259:159 260:160 261:161 262:162 263:163 264:164 265:165 266:166 267:167 268:168 269:169 270:170 271:171 272:172 273:173 274:174 275:175 276:176 277:177 278:178 279:179 280:179 281:180 282:181 283:182 284:183 285:184 286:185 287:185 288:186 289:187 290:188 291:189 292:190 293:191 294:191 295:192 296:193 297:194 298:195 299:196 300:197 301:198 302:199 303:199 304:200 305:201 306:202 307:203 308:204 309:205 310:206 311:207 312:208 313:209 314:210 315:211 316:212 317:212 318:213 319:214 320:215 321:216 322:217 323:217 324:217 325:218 326:219 327:220 328:221 329:222 330:223 331:224 332:225 333:225 334:226 335:227 336:228 337:228 338:228 339:228 340:229 341:230 342:231 343:232 344:233 345:234 346:235 347:236 348:237 349:238 350:238 351:239 352:239 353:240 354:241 355:241 356:242 357:243 358:244 359:245 360:246 361:247 362:248 363:249 364:250 365:251 366:252 367:252\n",
            "INFO:tensorflow:token_is_max_context: 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True\n",
            "INFO:tensorflow:input_ids: 101 2006 2233 2484 1010 2294 1010 1996 2118 2949 1996 5309 1997 1996 6282 1011 7456 1006 14210 1010 2199 2054 25525 1007 11833 2267 1006 2006 1996 2264 2203 1997 2146 2479 1007 3200 2013 2146 2479 2118 2007 1996 7848 2000 4503 2009 2004 1037 2440 2267 3721 7995 2006 3834 3454 3141 2000 1996 4044 1998 15169 1012 102 1999 2526 1010 1996 2118 2511 1037 3739 1999 7128 2007 1996 3098 1997 16104 9566 7128 1012 1996 2434 2609 2001 2012 22649 2380 3927 2148 1025 1037 10947 3169 2441 1999 2397 2263 1999 1996 5516 2311 2006 1996 2353 2723 1997 4229 2581 2380 3927 2148 1012 1996 2118 10495 3136 1999 2249 2000 2074 1996 3822 2723 1997 4229 2581 2380 3927 2148 1010 2007 1037 9823 4211 2105 1996 3420 2012 7886 2264 15045 2395 1012 1996 2324 1010 2199 1011 2675 1011 3329 1006 1015 1010 6352 25525 1007 2609 4473 16104 9566 2000 3749 2658 1998 4619 5352 9416 2875 2493 1999 2047 2259 2103 1025 8324 5352 2024 2218 3952 2076 1996 2621 1998 3467 6521 1012 9281 1998 2569 2824 2202 2173 2802 1996 2095 1012 1999 2337 2418 2174 1010 1996 10084 2005 2023 3721 2001 12527 1010 1998 2045 2024 2053 4280 3253 2012 2023 3295 1012 2006 2233 2484 1010 2294 1010 1996 2118 2949 1996 5309 1997 1996 6282 1011 7456 1006 14210 1010 2199 25525 1007 11833 2267 1006 2006 1996 2264 2203 1997 2146 2479 1007 3200 2013 2146 2479 2118 2007 1996 7848 2000 4503 2009 2004 1037 2440 2267 3721 7995 2006 3834 3454 3141 2000 1996 4044 1998 15169 1012 16104 9566 4423 2049 2434 2565 1010 2318 1999 1996 2991 1997 2384 1010 2043 2009 3253 2019 8324 3884 4163 2565 1010 2007 4252 1998 2470 4128 2012 1996 3721 12019 2013 2146 2479 2118 1012 2019 10316 1997 2055 1016 1010 2199 2493 2003 3517 2306 1996 2279 2274 2086 1012 2934 3235 8040 6806 5643 2078 2001 2805 9455 4670 1997 11833 3721 2006 2257 1017 1010 2294 1010 1998 5680 2923 2984 7247 2001 2805 4670 1998 3580 2343 1999 2233 2268 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 63\n",
            "INFO:tensorflow:end_position: 63\n",
            "INFO:tensorflow:answer: in\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000008\n",
            "INFO:tensorflow:example_index: 8\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] the what is governed by the state university of new york board of trustees : a body of eighteen members which regulate all the individual units of the sun ##y system . [SEP] the university is governed by the state university of new york board of trustees : a body of eighteen members which regulate all the individual units of the sun ##y system . the trustees have the authority to appoint the president of each state - operated institution , grant all degree diploma ##s and certificates for the completion of studies at any state - operated campus , and regulation of admissions , tuition , cu ##rri ##cula , and all other matters pertaining to the operation and administration of each state - operated campus . the president of stony brook is the principal executive officer of the university . the position was first held by john francis lee and is held by the fifth president in the institution ' s history , dr . samuel stanley jr , who has served since may 2009 . stony brook ' s financial endowment is managed by the stony brook foundation . the foundation was established in 1965 as a not - for - profit corporation under the new york state education law . it is the second largest endowment among state university of new york university centers behind the university at buffalo . however , the university ' s endowment remains far below the average of its association of american universities peers . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 34:0 35:1 36:2 37:3 38:4 39:5 40:6 41:7 42:8 43:9 44:10 45:11 46:12 47:13 48:13 49:14 50:15 51:16 52:17 53:18 54:19 55:20 56:21 57:22 58:23 59:24 60:25 61:26 62:27 63:27 64:28 65:28 66:29 67:30 68:31 69:32 70:33 71:34 72:35 73:36 74:37 75:38 76:39 77:40 78:40 79:40 80:41 81:41 82:42 83:43 84:44 85:45 86:45 87:46 88:47 89:48 90:49 91:50 92:51 93:52 94:53 95:54 96:55 97:55 98:55 99:56 100:56 101:57 102:58 103:59 104:60 105:60 106:61 107:61 108:62 109:62 110:62 111:62 112:63 113:64 114:65 115:66 116:67 117:68 118:69 119:70 120:71 121:72 122:73 123:74 124:75 125:75 126:75 127:76 128:76 129:77 130:78 131:79 132:80 133:81 134:82 135:83 136:84 137:85 138:86 139:87 140:88 141:89 142:89 143:90 144:91 145:92 146:93 147:94 148:95 149:96 150:97 151:98 152:99 153:100 154:101 155:102 156:103 157:104 158:105 159:106 160:107 161:108 162:108 163:108 164:109 165:109 166:110 167:110 168:111 169:112 170:113 171:113 172:114 173:115 174:116 175:117 176:118 177:119 178:119 179:119 180:120 181:120 182:120 183:121 184:122 185:123 186:124 187:125 188:126 189:127 190:128 191:129 192:129 193:130 194:131 195:132 196:133 197:134 198:135 199:136 200:137 201:138 202:138 203:138 204:138 205:138 206:139 207:140 208:141 209:142 210:143 211:144 212:145 213:146 214:146 215:147 216:148 217:149 218:150 219:151 220:152 221:153 222:154 223:155 224:156 225:157 226:158 227:159 228:160 229:161 230:162 231:163 232:164 233:165 234:165 235:166 236:166 237:167 238:168 239:168 240:168 241:169 242:170 243:171 244:172 245:173 246:174 247:175 248:176 249:177 250:178 251:179 252:180 253:181 254:181\n",
            "INFO:tensorflow:token_is_max_context: 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True\n",
            "INFO:tensorflow:input_ids: 101 1996 2054 2003 9950 2011 1996 2110 2118 1997 2047 2259 2604 1997 9360 1024 1037 2303 1997 7763 2372 2029 15176 2035 1996 3265 3197 1997 1996 3103 2100 2291 1012 102 1996 2118 2003 9950 2011 1996 2110 2118 1997 2047 2259 2604 1997 9360 1024 1037 2303 1997 7763 2372 2029 15176 2035 1996 3265 3197 1997 1996 3103 2100 2291 1012 1996 9360 2031 1996 3691 2000 16823 1996 2343 1997 2169 2110 1011 3498 5145 1010 3946 2035 3014 9827 2015 1998 17987 2005 1996 6503 1997 2913 2012 2151 2110 1011 3498 3721 1010 1998 7816 1997 20247 1010 15413 1010 12731 18752 19879 1010 1998 2035 2060 5609 20246 2000 1996 3169 1998 3447 1997 2169 2110 1011 3498 3721 1012 1996 2343 1997 16104 9566 2003 1996 4054 3237 2961 1997 1996 2118 1012 1996 2597 2001 2034 2218 2011 2198 4557 3389 1998 2003 2218 2011 1996 3587 2343 1999 1996 5145 1005 1055 2381 1010 2852 1012 5212 6156 3781 1010 2040 2038 2366 2144 2089 2268 1012 16104 9566 1005 1055 3361 15108 2003 3266 2011 1996 16104 9566 3192 1012 1996 3192 2001 2511 1999 3551 2004 1037 2025 1011 2005 1011 5618 3840 2104 1996 2047 2259 2110 2495 2375 1012 2009 2003 1996 2117 2922 15108 2426 2110 2118 1997 2047 2259 2118 6401 2369 1996 2118 2012 6901 1012 2174 1010 1996 2118 1005 1055 15108 3464 2521 2917 1996 2779 1997 2049 2523 1997 2137 5534 12746 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 35\n",
            "INFO:tensorflow:end_position: 35\n",
            "INFO:tensorflow:answer: university\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000009\n",
            "INFO:tensorflow:example_index: 9\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] although the marine sciences and graduate writing programs are still in session at what , undergraduate ##s were relocated to the main campus . [SEP] southampton campus , with its prominent windmill ##on april 7 , 2010 , the university had suspended residential programs and transferred sustainability programs to the main campus . the change was prompted by severe state budget cuts . although the marine sciences and graduate writing programs are still in session at southampton , undergraduate ##s were relocated to the main campus . as a result of the suspension of residential programs , all dining services and retail operations were suspended by the faculty student association . the old liu radio station and national public radio affiliate no longer operate on the campus . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 26:0 27:1 28:1 29:2 30:3 31:4 32:5 33:5 34:6 35:7 36:7 37:8 38:8 39:9 40:10 41:11 42:12 43:13 44:14 45:15 46:16 47:17 48:18 49:19 50:20 51:21 52:22 53:22 54:23 55:24 56:25 57:26 58:27 59:28 60:29 61:30 62:31 63:31 64:32 65:33 66:34 67:35 68:36 69:37 70:38 71:39 72:40 73:41 74:42 75:43 76:44 77:45 78:45 79:46 80:46 81:47 82:48 83:49 84:50 85:51 86:52 87:52 88:53 89:54 90:55 91:56 92:57 93:58 94:59 95:60 96:61 97:61 98:62 99:63 100:64 101:65 102:66 103:67 104:68 105:69 106:70 107:71 108:72 109:73 110:74 111:74 112:75 113:76 114:77 115:78 116:79 117:80 118:81 119:82 120:83 121:84 122:85 123:86 124:87 125:88 126:89 127:90 128:90\n",
            "INFO:tensorflow:token_is_max_context: 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True\n",
            "INFO:tensorflow:input_ids: 101 2348 1996 3884 4163 1998 4619 3015 3454 2024 2145 1999 5219 2012 2054 1010 8324 2015 2020 7448 2000 1996 2364 3721 1012 102 11833 3721 1010 2007 2049 4069 25367 2239 2258 1021 1010 2230 1010 1996 2118 2018 6731 5647 3454 1998 4015 15169 3454 2000 1996 2364 3721 1012 1996 2689 2001 9469 2011 5729 2110 5166 7659 1012 2348 1996 3884 4163 1998 4619 3015 3454 2024 2145 1999 5219 2012 11833 1010 8324 2015 2020 7448 2000 1996 2364 3721 1012 2004 1037 2765 1997 1996 8636 1997 5647 3454 1010 2035 7759 2578 1998 7027 3136 2020 6731 2011 1996 4513 3076 2523 1012 1996 2214 8607 2557 2276 1998 2120 2270 2557 8727 2053 2936 5452 2006 1996 3721 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 26\n",
            "INFO:tensorflow:end_position: 26\n",
            "INFO:tensorflow:answer: southampton\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000010\n",
            "INFO:tensorflow:example_index: 10\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] at the same time , residential housing was expanded to 3 , 000 , the stony brook union opened in 1970 , and in 1971 , the massive expansion project for the campus library ( named in memory of frank melville jr . , father of philanthropist what ) was completed . [SEP] ward melville , a philanthropist and businessman from the three village area in western suffolk county donated over 400 acres of land to the state for the development of a state university in 1966 the university set forth initial timetable ##s for the development of the health science center which would house the university ' s health programs and hospital . despite the budget ##ary concerns and challenges from albany the university released a formal ##ized plan early in 1968 and funding for recruitment of faculty was provided . at the same time , residential housing was expanded to 3 , 000 , the stony brook union opened in 1970 , and in 1971 , the massive expansion project for the campus library ( named in memory of frank melville jr . , father of philanthropist ward melville ) was completed . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 54:0 55:1 56:1 57:2 58:3 59:4 60:5 61:6 62:7 63:8 64:9 65:10 66:11 67:12 68:13 69:14 70:15 71:16 72:17 73:18 74:19 75:20 76:21 77:22 78:23 79:24 80:25 81:26 82:27 83:28 84:29 85:30 86:31 87:32 88:33 89:34 90:35 91:36 92:37 93:38 94:38 95:39 96:40 97:41 98:42 99:43 100:44 101:45 102:46 103:47 104:48 105:49 106:50 107:51 108:51 109:51 110:52 111:53 112:54 113:55 114:55 115:56 116:57 117:58 118:58 119:59 120:60 121:61 122:62 123:63 124:64 125:65 126:66 127:67 128:68 129:68 130:69 131:70 132:71 133:72 134:73 135:74 136:75 137:76 138:77 139:78 140:79 141:80 142:80 143:81 144:82 145:83 146:84 147:84 148:85 149:86 150:87 151:88 152:89 153:90 154:90 155:90 156:90 157:91 158:92 159:93 160:94 161:95 162:96 163:97 164:97 165:98 166:99 167:100 168:100 169:101 170:102 171:103 172:104 173:105 174:106 175:107 176:108 177:109 178:109 179:110 180:111 181:112 182:113 183:114 184:115 185:115 186:115 187:116 188:117 189:118 190:119 191:120 192:120 193:121 194:122 195:122\n",
            "INFO:tensorflow:token_is_max_context: 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True\n",
            "INFO:tensorflow:input_ids: 101 2012 1996 2168 2051 1010 5647 3847 2001 4423 2000 1017 1010 2199 1010 1996 16104 9566 2586 2441 1999 3359 1010 1998 1999 3411 1010 1996 5294 4935 2622 2005 1996 3721 3075 1006 2315 1999 3638 1997 3581 20154 3781 1012 1010 2269 1997 15246 2054 1007 2001 2949 1012 102 4829 20154 1010 1037 15246 1998 6883 2013 1996 2093 2352 2181 1999 2530 12291 2221 6955 2058 4278 4631 1997 2455 2000 1996 2110 2005 1996 2458 1997 1037 2110 2118 1999 3547 1996 2118 2275 5743 3988 23839 2015 2005 1996 2458 1997 1996 2740 2671 2415 2029 2052 2160 1996 2118 1005 1055 2740 3454 1998 2902 1012 2750 1996 5166 5649 5936 1998 7860 2013 10283 1996 2118 2207 1037 5337 3550 2933 2220 1999 3380 1998 4804 2005 15680 1997 4513 2001 3024 1012 2012 1996 2168 2051 1010 5647 3847 2001 4423 2000 1017 1010 2199 1010 1996 16104 9566 2586 2441 1999 3359 1010 1998 1999 3411 1010 1996 5294 4935 2622 2005 1996 3721 3075 1006 2315 1999 3638 1997 3581 20154 3781 1012 1010 2269 1997 15246 4829 20154 1007 2001 2949 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 54\n",
            "INFO:tensorflow:end_position: 55\n",
            "INFO:tensorflow:answer: ward melville\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000011\n",
            "INFO:tensorflow:example_index: 11\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] the marine sciences research center , the original institute for marine studies , was incorporated into the new what ( so ##mas ) on june 15 , 2007 . [SEP] the school of marine and atmospheric sciences ( so ##mas ) is the sun ##y center for marine and atmospheric research , education , and public service . more than 300 graduate and undergraduate students from 16 different nations work and study at so ##mas . the school ' s students study coastal ocean ##ographic processes and atmospheric sciences in a natural and academic setting that offers abundant opportunities for conducting field work , solving real problems in both local and distant environments , and learning to express their opinions in the weekly seminars . the marine sciences research center , the original institute for marine studies , was incorporated into the new school of marine and atmospheric sciences ( so ##mas ) on june 15 , 2007 . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 31:0 32:1 33:2 34:3 35:4 36:5 37:6 38:7 39:7 40:7 41:7 42:8 43:9 44:10 45:10 46:11 47:12 48:13 49:14 50:15 51:16 52:16 53:17 54:17 55:18 56:19 57:20 58:20 59:21 60:22 61:23 62:24 63:25 64:26 65:27 66:28 67:29 68:30 69:31 70:32 71:33 72:34 73:35 74:36 75:36 76:36 77:37 78:38 79:38 80:38 81:39 82:40 83:41 84:42 85:42 86:43 87:44 88:45 89:46 90:47 91:48 92:49 93:50 94:51 95:52 96:53 97:54 98:55 99:56 100:57 101:58 102:59 103:60 104:60 105:61 106:62 107:63 108:64 109:65 110:66 111:67 112:68 113:69 114:69 115:70 116:71 117:72 118:73 119:74 120:75 121:76 122:77 123:78 124:79 125:79 126:80 127:81 128:82 129:83 130:84 131:84 132:85 133:86 134:87 135:88 136:89 137:90 138:90 139:91 140:92 141:93 142:94 143:95 144:96 145:97 146:98 147:99 148:100 149:101 150:102 151:102 152:102 153:102 154:103 155:104 156:105 157:105 158:106 159:106\n",
            "INFO:tensorflow:token_is_max_context: 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True\n",
            "INFO:tensorflow:input_ids: 101 1996 3884 4163 2470 2415 1010 1996 2434 2820 2005 3884 2913 1010 2001 5100 2046 1996 2047 2054 1006 2061 9335 1007 2006 2238 2321 1010 2289 1012 102 1996 2082 1997 3884 1998 12483 4163 1006 2061 9335 1007 2003 1996 3103 2100 2415 2005 3884 1998 12483 2470 1010 2495 1010 1998 2270 2326 1012 2062 2084 3998 4619 1998 8324 2493 2013 2385 2367 3741 2147 1998 2817 2012 2061 9335 1012 1996 2082 1005 1055 2493 2817 5780 4153 13705 6194 1998 12483 4163 1999 1037 3019 1998 3834 4292 2008 4107 12990 6695 2005 9283 2492 2147 1010 13729 2613 3471 1999 2119 2334 1998 6802 10058 1010 1998 4083 2000 4671 2037 10740 1999 1996 4882 17239 1012 1996 3884 4163 2470 2415 1010 1996 2434 2820 2005 3884 2913 1010 2001 5100 2046 1996 2047 2082 1997 3884 1998 12483 4163 1006 2061 9335 1007 2006 2238 2321 1010 2289 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:start_position: 32\n",
            "INFO:tensorflow:end_position: 37\n",
            "INFO:tensorflow:answer: school of marine and atmospheric sciences\n",
            "INFO:tensorflow:***** Running training *****\n",
            "INFO:tensorflow:  Num orig examples = 12\n",
            "INFO:tensorflow:  Num split examples = 12\n",
            "INFO:tensorflow:  Batch size = 32\n",
            "INFO:tensorflow:  Num steps = 1\n",
            "WARNING:tensorflow:From <ipython-input-12-2d92a7f8d47e>:575: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running train on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = end_positions, shape = (32,)\n",
            "INFO:tensorflow:  name = input_ids, shape = (32, 384)\n",
            "INFO:tensorflow:  name = input_mask, shape = (32, 384)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (32, 384)\n",
            "INFO:tensorflow:  name = start_positions, shape = (32,)\n",
            "INFO:tensorflow:  name = unique_ids, shape = (32,)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /Downloads/output/model.ckpt.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}